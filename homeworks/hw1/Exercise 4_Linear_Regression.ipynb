{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro to Python: Exercise 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear regression with one variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the first part of the exercise, we're tasked with implementing linear regression with one variable to predict profits for a food truck. Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by importing some libraries and examining the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the data from the CSV file using Panda library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Population</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.1101</td>\n",
              "      <td>17.5920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.5277</td>\n",
              "      <td>9.1302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.5186</td>\n",
              "      <td>13.6620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0032</td>\n",
              "      <td>11.8540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.8598</td>\n",
              "      <td>6.8233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Population   Profit\n",
              "0      6.1101  17.5920\n",
              "1      5.5277   9.1302\n",
              "2      8.5186  13.6620\n",
              "3      7.0032  11.8540\n",
              "4      5.8598   6.8233"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"data/ex1data1.txt\", header=None, names=['Population', 'Profit'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Population</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>97.000000</td>\n",
              "      <td>97.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.159800</td>\n",
              "      <td>5.839135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.869884</td>\n",
              "      <td>5.510262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.026900</td>\n",
              "      <td>-2.680700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.707700</td>\n",
              "      <td>1.986900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.589400</td>\n",
              "      <td>4.562300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.578100</td>\n",
              "      <td>7.046700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22.203000</td>\n",
              "      <td>24.147000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Population     Profit\n",
              "count   97.000000  97.000000\n",
              "mean     8.159800   5.839135\n",
              "std      3.869884   5.510262\n",
              "min      5.026900  -2.680700\n",
              "25%      5.707700   1.986900\n",
              "50%      6.589400   4.562300\n",
              "75%      8.578100   7.046700\n",
              "max     22.203000  24.147000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot it to get a better idea of what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='Population', ylabel='Profit'>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+QAAAKnCAYAAAAP5odnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARrBJREFUeJzt3QuUXVV9P/A9JCEwCRlIZkKIhDxIDD4QKRLEaOS1RLA8xKqgFoEUC4VQRJZKVxGodcUHdanU11rVYFqNSguiaKUKgWjkbaKgkiYQAv55ZBLMDMkIicn9r33amc5NZu7cuXNn9rn3fj5rzUrOvvM4uWfuTL5n//ZvNxUKhUIAAAAARtReI/vlAAAAgEggBwAAgAQEcgAAAEhAIAcAAIAEBHIAAABIQCAHAACABARyAAAASEAgBwAAgARGhzq3a9eu8PTTT4f99tsvNDU1pT4dAAAA6lyhUAgvvPBCmDp1athrr70aN5DHMD5t2rTUpwEAAECDeeqpp8LBBx/cuIE8zox3PxETJkxIfToAAADUuc7OzmxiuDuPNmwg7y5Tj2FcIAcAAGCkDLRsWlM3AAAASEAgBwAAgAQEcgAAAGi0QL548eJw9NFHZwvdJ0+eHM4888ywZs2aovc57rjjsrr73m8XXXRRsnMGAACAmg/kd999d7jkkkvCvffeG37yk5+EHTt2hLe85S1h27ZtRe934YUXhmeeeabn7dOf/nSycwYAAIBqSNpl/cc//nHR8Y033pjNlD/00ENhwYIFPePNzc1hypQpCc4QAAAAGmANeUdHR/bnxIkTi8a/+c1vhtbW1vDqV786XHXVVaGrq6vfz/HSSy9le771fgMAAIC8yc0+5Lt27QqXX355mD9/fha8u73nPe8J06dPD1OnTg2//vWvw0c+8pFsnfnNN9/c77r06667bgTPHAAAAAavqVAoFEIOXHzxxeE///M/w89//vNw8MEH9/t+d955ZzjxxBPDunXrwqGHHtrnDHl86xZnyKdNm5bNvk+YMGHYzh8AAAC6c2hLS8uAOTQXM+SXXnppuO2228KKFStKhvHomGOOyf7sL5CPHTs2ewMAAIA8SxrI4+T8okWLwi233BLuuuuuMHPmzAE/ZvXq1dmfBx100AicIQAAANRhII9bnn3rW98Kt956a7YX+bPPPpuNx6n9fffdNzz22GPZ46eeemqYNGlStob8gx/8YNaB/TWveU3KUwcAAIDaXUPe1NTU5/iSJUvCeeedF5566qnwvve9LzzyyCPZ3uRxLfjb3/728Pd///dlrwcvt3YfAAAAGmYN+UD3AmIAv/vuu0fsfAAAAKAh9yEHAACARiGQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJJB0H3IAAAAo1+PtW8OG57vCjEnjwszWcaHWCeQAAADk2pau7eGyZavDirXtPWML5rSFG845MrQ0jwm1Ssk6AAAAuXbZstVh5bpNRWPxeNGyVaGWCeQAAADkukx9xdr2sLNQKBqPx3F8/aZtoVYJ5AAAAOTWhue7Sj7+xGaBHAAAAKpu+sTmko/HBm+1ygw5AAAAuTWrbXzWwG1UU1PReDyO47XcbV0gBwAAINduOOfIMH92a9FYPI7jtcy2ZwAAAORaS/OYsHThvKyBW1wzbh9yAAAAGEEzW8fVdIn67pSsAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACo1N8UQAAoPY83r41bHi+K8yYNC7MbB2X+nSg5gnkAABASVu6tofLlq0OK9a294wtmNMWbjjnyNDSPMazBxVSsg4AAJQUw/jKdZuKxuLxomWrPHMwBAI5AABQskw9zozvLBSKxuNxHF+/aZtnDyokkAMAAP2Ka8ZLeWKzQA6VEsgBAIB+TZ/YXPLZiQ3egMoI5AAAQL9mtY3PGriNamoqGo/HcVy3daicQA4AAJQUu6nPn91aNBaP4zhQOdueAQAAJcWtzZYunJc1cItrxu1DDtUhkAMAAGWJ5elK1KF6lKwDAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJDA6xRcFAACoRY+3bw0bnu8KMyaNCzNbx6U+HWqcQA4AADCALV3bw2XLVocVa9t7xhbMaQs3nHNkaGke4/mjIkrWAQAABhDD+Mp1m4rG4vGiZas8d1RMIAcAABigTD3OjO8sFIrG43EcX79pm+ePigjkAAAAJcQ146U8sVkgpzICOQAAQAnTJzaXfH5igzeohEAOAABQwqy28VkDt1FNTUXj8TiO67ZOpQRyAACAAcRu6vNntxaNxeM4DpWy7RkAAMAA4tZmSxfOyxq4xTXj9iGnGgRyAACAMsXydCXqVIuSdQAAAEhAIAcAAIAEBHIAAABIQCAHAACABARyAAAASEAgBwAAgAQEcgAAAEjAPuQAAAAVerx9a9jwfFeYMcn+5AyeQA4AADBIW7q2h8uWrQ4r1rb3jC2Y0xZuOOfI0NI8xvNJWZSsAwAADFIM4yvXbSoai8eLlq3yXFI2gRwAAGCQZepxZnxnoVA0Ho/j+PpN2zyflEUgBwAAGIS4ZryUJzYL5JRHIAcAABiE6RObSz4eG7xBOQRyAACAQZjVNj5r4DaqqaloPB7H8ZmtAjnlEcgBAAAGKXZTnz+7tWgsHsdxKJdtzwAAAAYpbm22dOG8rIFbXDNuH3IqIZADAABUKJanK1GnUkrWAQAAIAGBHAAAABIQyAEAACABgRwAAAASEMgBAAAgAYEcAAAAEhDIAQAAIAGBHAAAABIQyAEAACABgRwAAAAaLZAvXrw4HH300WG//fYLkydPDmeeeWZYs2ZN0fu8+OKL4ZJLLgmTJk0K48ePD+94xzvCc889l+ycAQAAoOYD+d13352F7XvvvTf85Cc/CTt27AhvectbwrZt23re54Mf/GD4wQ9+EG666abs/Z9++ulw1llnpTxtAAAAGLKmQqFQCDnR3t6ezZTH4L1gwYLQ0dER2trawre+9a3wF3/xF9n7PProo+EVr3hFuOeee8LrX//6AT9nZ2dnaGlpyT7XhAkTRuBfAQAAQCPrLDOH5moNeTzZaOLEidmfDz30UDZrftJJJ/W8z2GHHRYOOeSQLJD35aWXXsr+8b3fAAAAIG9yE8h37doVLr/88jB//vzw6le/Oht79tlnw9577x3233//ovc98MADs8f6W5ce70R0v02bNm1Ezh8AAABqMpDHteSPPPJI+Pa3vz2kz3PVVVdlM+3db0899VTVzhEAAACqZXTIgUsvvTTcdtttYcWKFeHggw/uGZ8yZUrYvn172LJlS9EseeyyHh/ry9ixY7M3AAAAyLOkM+Sxn1wM47fccku48847w8yZM4seP+qoo8KYMWPCHXfc0TMWt0V78sknw7HHHpvgjAEAAKAOZshjmXrsoH7rrbdme5F3rwuPa7/33Xff7M+FCxeGK664Imv0FrvTLVq0KAvj5XRYBwAAgLxKuu1ZU1NTn+NLliwJ5513Xvb3F198MXzoQx8Ky5Ytyzqon3zyyeFLX/pSvyXru7PtGQAAACOp3Byaq33Ih4NADgAAwEiqyX3IAQAAoFEI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJjE7xRQEAAEjn8fatYcPzXWHGpHFhZus4lyIRgRwAAKBBbOnaHi5btjqsWNveM7ZgTlu44ZwjQ0vzmKTn1oiUrAMAADSIGMZXrttUNBaPFy1bleycGplADgAA0CBl6nFmfGehUDQej+P4+k3bkp1boxLIAQAAGkBcM17KE5sF8pEmkAMAADSA6RObSz4eG7wxsgRyAACABjCrbXzWwG1UU1PReDyO47qtjzyBnGFdo7J8zUZrUQAAICdiN/X5s1uLxuJxHGfk2faMqrOVAgAA5FPc2mzpwnnZpFlcM24f8rTMkFN1tlIAAIB8i+Xpx8+drEw9MYGcqrKVAgAAQHkEcqrKVgoAAADlEcipKlspAAAAlEcgp6pspQAAAFAegZyqs5UCAADAwGx7RtXZSgEAAGBgAjnDupVCfAMAAGBPStYBAAAgATPkAABA2R5v35ptdTtjkmpIGCqBHAAAGNCWru3hsmWrw4q17T1jC+a0ZQ19Yw8hYPCUrAMAAAOKYXzluk1FY/F40bJVnj2okEAOAAAMWKYeZ8Z3FgpF4/E4jq/ftM0zCBUQyAEAgJLimvFSntgskEMlBHIAAKCk6RObSz4eG7wBgyeQAwAAJc1qG581cBvV1FQ0Ho/j+MxWgRwqIZADAAADit3U589uLRqLx3EcqIxtzwAAgAHFrc2WLpyXNXCLa8btQw5DJ5ADAABli+XpStShOpSsAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkMDrFFwUA6O3x9q1hw/NdYcakcWFm6zhPDgANQSAHAJLZ0rU9XLZsdVixtr1nbMGctnDDOUeGluYxrgwAdU3JOgCQTAzjK9dtKhqLx4uWrUp2TgAwUgRyACBZmXqcGd9ZKBSNx+M4vn7TNlcGgLomkAMAScQ146U8sVkgB6C+CeQAQBLTJzaXfDw2eAOAeiaQAwBJzGobnzVwG9XUVDQej+O4busA1DuBHABIJnZTnz+7tWgsHsdxAKh3tj0DAJKJW5stXTgva+AW14zbhxyARiKQAwDJxfJ0JeoANJqkJesrVqwIp512Wpg6dWpoamoK3/ve94oeP++887Lx3m9vfetbk50vAAAA1EUg37ZtWzjiiCPCF7/4xX7fJwbwZ555pudt2bJlI3qOAAAAUHcl66ecckr2VsrYsWPDlClTRuycAAAAYCTkvsv6XXfdFSZPnhzmzp0bLr744rB58+bUpwQAAAD13dQtlqufddZZYebMmeGxxx4Lf/d3f5fNqN9zzz1h1KhRfX7MSy+9lL116+zsHMEzBgAAgDoI5GeffXbP3w8//PDwmte8Jhx66KHZrPmJJ57Y58csXrw4XHfddSN4lgAAAFCHJeu9zZo1K7S2toZ169b1+z5XXXVV6Ojo6Hl76qmnRvQcAQAAoOZnyHf3+9//PltDftBBB5VsAhffAKBRPN6+NWx4vivMmGQvbwCoJUkD+datW4tmu9evXx9Wr14dJk6cmL3F0vN3vOMdWZf1uIb8wx/+cJg9e3Y4+eSTU542AOTClq7t4bJlq8OKte09YwvmtIUbzjkytDSPSXpuAEDOS9YffPDBcOSRR2Zv0RVXXJH9/WMf+1jWtO3Xv/51OP3008PLX/7ysHDhwnDUUUeFn/3sZ2bAASCELIyvXLep6LmIx4uWrfL8AEANSDpDftxxx4VCodDv47fffvuIng8A1FKZeu+Z8W47C4VsfP2mbWFm67gk5wYA1GFTNwDgf8Q146U8sXmbpwoAck4gB4AaNH1ic8nHY4M3ACDfBHIAqEGz2sZnDdxGNTUVjcfjOK5cHQDyTyAHgBoVu6nPn91aNBaP4zgAkH81tQ85APB/4tZmSxfOyxq4xTXj9iEHgNoikANAjYvl6UrUAaD2KFkHAACABARyAAAASEAgBwAAgAQEcgAAAEhAIAcAAIAEBHIAAABIQCAHAACABARyAAAASEAgBwAAgAQEcgAAAEhAIAcAAIAEBHIAAABIYHSKLwrUtsfbt4YNz3eFGZPGhZmt41KfDgAA1CSBHCjblq7t4bJlq8OKte09YwvmtIUbzjkytDSP8UwCAMAgKFkHyhbD+Mp1m4rG4vGiZas8iwAAMEgCOVB2mXqcGd9ZKBSNx+M4vn7TNs8kVPjaWr5mo9cQADQgJetAWeKa8VKe2LzNenIYBEtAAAAz5EBZpk9sLvl4bPAGlM8SEABAIAfKMqttfNbAbVRTU9F4PI7juq1D+SwBAQAigRwoW+ymPn92a9FYPI7jQHWXgAAA9c8acqBscWuzpQvnZc2nYmCwDzlUxhIQAEAgByoSy9OVqMPQl4DEbQN771wQl4DEqhOvLwBoDErWASABS0AAACXrAJCAJSAAgEAOAAlZAgIAjUvJOgAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAICOQAAACQgkAMAAEACAjkAAAAkIJADAABAAgI5AAAAJCCQAwAAQAKjU3xRgGp6vH1r2PB8V5gxaVyY2TrOkwsAQE0QyIGataVre7hs2eqwYm17z9iCOW3hhnOODC3NY5KeGwAADETJOlCzYhhfuW5T0Vg8XrRsVbJzAuqr+mb5mo1h/aZtqU8FgDplhhyoyXLx+HV7z4x321koZOPxP9DK14FKqL4BYKQI5EBN/oc13gQo5YnNAjlQ/eqbpQvneVoBqBol60BNlotPn9hc8vE4Yw9QafVNrLbpr/oGAKpFIIf/Za1g+c9HHv7DOqttfDYjP6qpqWg8Hsdx5erAcFXfAEC1KFmn4aUuva7F5yMv5eLxnOKMfO9znT+7NRsHqITqGwBGkkBOw7NWcPDPR17+wxpvEMRzijPy8SaAfciBalXfxJ97vauAYvVNvOGn+gaAalKyTkPLQ+l1LT4feSsXj1/v+LmT/UcZqIpYZRPDd2+qbwAYDmbIaWh5Kb2uxedDuThQr1TfADBSBHIaWl5Kr2vx+fAfVqDexRuQjXRTFoCRp2Sdhpa30utafD6UiwMAQGUEchqetYLFPB8AADAymgqF3bo31ZnOzs7Q0tISOjo6woQJE1KfDjmmU7fnAwAARjKHWkMO/8tawWKeDwAAGF5K1gEAACABgRwAAABqJZA/+eSToa+l53EsPgYAAAAMQyCfOXNmaG9v32P8+eefzx4DAAAAhiGQx5nwpt32KY62bt0a9tlnn0o+JQAAADSUQXVZv+KKK7I/Yxi/+uqrQ3Nzc89jO3fuDPfdd1947WtfW/2zBAAAgEYO5KtWreqZIX/44YfD3nvv3fNY/PsRRxwRrrzyyuqfJQAAADRyIF++fHn25/nnnx8+//nPl9zgHAAAAKhSIO+2ZMmSSj4MAAAAGGwgP+uss8KNN96YzYrHv5dy8803l/tpAQAAoCGVHchbWlp6OqvHUN5Xl3UAAACgyoH87W9/e8+WZnGmHAAAABiBfchjIN+yZUv291GjRoWNGzcO4csCAABAYys7kLe1tYV77723Z9szJesAAAAwAiXrF110UTjjjDOyIB7fpkyZ0u/77ty5cwinBAAAAPWv7EB+7bXXhrPPPjusW7cunH766dnWZ/vvv//wnh0AAADUqUHtQ37YYYdlb9dcc0145zvfGZqbm4fvzAAAAKCONRXigvAKtbe3hzVr1mR/nzt3brbOPG86OzuzLds6Ojqy7doAAAAgDzm07KZuvXV1dYULLrggTJ06NSxYsCB7i39fuHBh9hgAAABQWkWB/IMf/GC4++67w/e///1sK7T4duutt2ZjH/rQhyr5lAAAANBQKipZb21tDf/+7/8ejjvuuKLx5cuXh3e9611ZKXteKFkHAACgrkrWDzzwwD3GJ0+erGQdAAAAylBRID/22GOzTusvvvhiz9gf//jHcN1112WPAQAAAFXc9qzb5z73ufDWt741HHzwweGII47Ixn71q1+FffbZJ9x+++2VfEoAAABoKBVvexbL1r/5zW+GRx99NDt+xSteEd773veGfffdN+SJNeQAAADkMYcOeoZ8x44d4bDDDgu33XZbuPDCC4d6ngAAANCQBr2GfMyYMUVrxwEAAIARaup2ySWXhE996lPhT3/6UyUfDgD08nj71rB8zcawftM2zwsANJCKmro98MAD4Y477gj/9V//FQ4//PAwbty4osdvvvnmap0fANStLV3bw2XLVocVa9t7xhbMaQs3nHNkaGkek/TcAICczpDvv//+4R3veEc4+eSTw9SpU7PF6r3fyrVixYpw2mmnZZ+jqakpfO973yt6PPab+9jHPhYOOuigrFncSSedFNauXVvJKQNA7sQwvnLdpqKxeLxo2apk5wQA5HSGfNeuXeEzn/lM+O///u+wffv2cMIJJ4Rrr7224s7q27Zty7ZNu+CCC8JZZ521x+Of/vSnwxe+8IXwjW98I8ycOTNcffXV2U2A3/72t9kWawBQy2XqvWfGu+0sFLLxWL4+s7W4Ag0AaOBA/olPfCIL4HGmOobwGJbb29vD17/+9Yq++CmnnJK99SXOjsf9zv/+7/8+nHHGGdnY0qVLw4EHHpjNpJ999tkVfU0AyIMNz3eVfPyJzQI5ANS7QZWsx0D8pS99Kdx+++1ZKP7BD36Q7UUeZ86rbf369eHZZ5/Nwn+3WA5/zDHHhHvuuaffj3vppZeyPd96vwFA3kyf2Fzy8RmTzI4DQL0bVCB/8sknw6mnntpzHMNyXPv99NNPV/3EYhiP4ox4b/G4+7G+LF68uGg9+7Rp06p+bgAwVLPaxmcN3EY1NRWNx+M4rlwdAOrfoAJ53OZs97XbcV/yHTt2hLy46qqrQkdHR8/bU089lfqUAKBPsZv6/NmtRWPxOI4DAPVvUGvI47ru8847L4wdO7Zn7MUXXwwXXXRR0dZn1dj2bMqUKdmfzz33XNZlvVs8fu1rX9vvx8Vz631+AJBXcWuzpQvnZQ3c4prxWKZuZhwAGsegAvn73//+Pcbe9773heEQu6rHUB73O+8O4HE9+H333RcuvvjiYfmaAJBCDOGCOAA0nkEF8iVLllT1i2/dujWsW7euqJHb6tWrw8SJE8MhhxwSLr/88vCP//iPYc6cOT3bnsU9y88888yqngcAAADkOpBX24MPPhiOP/74nuMrrriiZyb+xhtvDB/+8Iezvco/8IEPhC1btoQ3vvGN4cc//rE9yAEAAKh5TYW4MLyOxTL32G09NnibMGFC6tMBAACgznWWmUMH1WUdAAAAqA6BHAAAABIQyAEAACABgRwAAAASEMgBAAAgAYEcAAAAEhDIAQAAIIHRKb4oaTzevjVseL4rzJg0LsxsHecyAAAAJCSQN4AtXdvDZctWhxVr23vGFsxpCzecc2RoaR6T9NwAAAAalZL1BhDD+Mp1m4rG4vGiZauSnRMA6aqllq/ZGNZv2uYSAEBiZsgb4D9evWfGu+0sFLLx+B8y5esA9U+1FADkjxnyOhfXjJfyxGYzJACNQLUUAOSPQF7npk9sLvl4bPAGQGNUS8XqqP6qpQCAkSeQ17lZbeOzBm6jmpqKxuNxHFeuDlD/VEsBQD4J5A0gdlOfP7u1aCwex3EA6p9qKQDIJ03dGkDc2mzpwnlZSWJcM24fcoDGrJaKO2z0LluP1VLxBq1qKQBIwwx5A4n/4Tp+7mT/8QJoQKqlACB/zJADQANQLQUA+SOQA0CDVUspUQeAfFCyDgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkMDoFF8UAAbj8fatYcPzXWHGpHFhZus4Tx4AUBcEcgBya0vX9nDZstVhxdr2nrEFc9rCDeccGVqaxyQ9NwCAoVKyDkBuxTC+ct2morF4vGjZqmTnBABQLQI5ALktU48z4zsLhaLxeBzH12/aluzcAACqQSAHyEn4XL5mo5DZS1wzXsoTmwVyAKC2WUMOkJA10v2bPrG55HMXG7wBANQyM+QACVkj3b9ZbeOzBm6jmpqKxuNxHNdtHQCodQI5QCLWSA8sdlOfP7u1aCwex3EAgFqnZB0gx2ukG30WOG5ttnThvGxtfXw+7EMOANQTgRxgEDPaMURXKxRaI12++Hw3+s0JAKD+COQAiRqvda+Rjvtq997aK66RjmXZAigAQH2zhhwgYeM1a6QBABqXGXKAMhqv7S7OaMfxuLZ5KDPZ1kgDADQugRwgB43XrJEGAGg8StYBStB4DQCA4SKQA5TReC02WustHsdxjdcAAKiUQM6g19MuX7MxWzdLY3DNNV4DAGB4WENO0m2fyC/X/P9ovAYAwHAwQ07ybZ/IJ9d8T7E8/fi5k5WpAwBQFQI5ZW/7FLd56m/bJ+qLaw4AAMNPIKcq2z5RX1zzxqZvAADAyLCGnAHZ9qnxuOaNSd8AAICRZYacAdn2qfG45o1J3wAAgJElkFOW2E19/uzWorF4HMepT655Y9E3AABg5ClZp+xtn649/ZXhvvXPh6YQwjGzJuk0Xeds9dVYyukbELvMAwBQPQI5A7KutLHFEJbHIBZndGOInDEpn+dXa/QNAAAYeQI5Q1pXunThPM/gCIZJIbS+bxClvL7dfQPia7v3Foejmpqy5SluegAAVJ9ATlnrSnfXew9y/1Ef/jBZzyG0EW8Q7R6883J949eLz2Pv89ArAgBg+AjklGRdaT7CZD2E0Gqo9RtE/QXvP+3aFe57/Pnk11ffAACAkaXLOjWxrjQGseVrNmaBq9G6WOt+PbgbRHnW142Vn69tD794bPOgvy+GU7ypcfzcybm+uQEAUA/MkJPrdaV5KeVNWW0wXFUKtbgePS83iKo5u79rgI/T3RwAoH6ZISfX+1GXKtWuNZWGyWqH0HiT49yv3R9O+Ke7w/lLHgjHX39XdtzRtSPUyg2ieEOot3gcx/N8Y2GgGyu1eJMBAIChEcgpe13p8iuPC0vOPzr7Mx4P9wx1vZVqVxomqx1Ca/0mR8obREMx0I2VvYovb03cZAAAYGiUrJPb/ajrsaFcpV2sq9X9utabotVy47FSyz/mzZwYxozaS3dzAIAGI5CTW7W8XrjaYbJaIbSebnKM9A2iaih1YyVe41q7yQAAwNAI5ORW6oZyeQyTQw2h9XiTo5YMdGOlFm8yAABQOWvIybVaXS+cV7XcFK2e2FYMAICoqVDYrWNWnens7AwtLS2ho6MjTJgwIfXpUCGlvNUTu6nvXjZdq1vJAQBALedQgRwalJscAACQNpBbQw4NynplAABIyxpyAAAASEAgBwAAgASUrFOzHm/fmu2rbc9mAACgFgnk1JwtXdvDZctW6xIOAADUNCXr1JwYxleu21Q0Fo/jVl4AAAC1QiCn5srU4/7ZOwuFovF4HMfjVl4AAAC1QCCnpsQ146U8sVkgBwAAaoM15NSU6RObSz4eG7xRGU3yAABgZAnkOSIQDWxW2/iwYE5btma8d9n6qKamMH92a5jZKpAPliZ5AACQRlOhsNti3DrT2dkZWlpaQkdHR5gwYULII4FocDq6dmQN3OKa8W4xpN9wzpGhpXlM1a9PvTv3a/f3e4Nj6cJ5Sc8NAADqOYeaIc9513CBaE8xdMfnJTZwi2vG7UM+9CZ5u+vdJE/VAQAADA+BPDGBqHIxKAqLw98kz3MMAADDQ5f1xHQNL745sXzNRluXjSBN8gAAIB0z5IkJRNbQp6RJHgAApGOGPCeBKDbR6i0ex/FGKBcutYY+pUaZsY/N8GIDt97icRyvN41yTeuRawcA1CMz5DkQg8/uXcPrNRANZQ39SG0L12hd7xuhSV6jXdN64toBAPXMtmc5Us+BqD9xtvL8JQ/0+/iS848OR07bf0TDlG3A6o9rWrtcOwCgnrc9U7KeIzGEHz93csOE8XLW0E9q3ntES9q7Z+x778m9+4w9tcU1rV2uHQBQ7wRycrGGvj//cNtvRzQg63pff1zT2uXaAQD1TiAn+frQF17c3u/jD274Q8mPjyX+1aTrff0153JNa5drBwDUO03dcmakGpflRSxH/9XvOyr++Pg8VZNtwOqvOZdrWrtcOwCg3pkhz1FYic2LTvinu7MmZ8dff1d23NG1I9T7+tBdxdXoezh6xgEjui1cI20D1ijb27mmtcu1AwDqWa67rF977bXhuuuuKxqbO3duePTRR6ve3S61RuwkPFCH9Xi36I3/O4O6+7ZwIzGzOlJd7xuhKiL+G+PNpv4sv/K4Efm3N+JOBvXCtQMAakm5OTT3JeuvetWrwk9/+tOe49Gjc3/Kw7oXdyOtDz1q+gE9oTvFPtnxa9jvfOSac9XDNWX4uHYAQD3Kfcl6DOBTpkzpeWttLS4lrgeN2km4e33o7uXoezX9T5n6TRe/oWgGvN62hUtZwj3SNOcCAIAaDORr164NU6dODbNmzQrvfe97w5NPPlny/V966aWsPKD3W941cljpa33oG2e3hX859+hQz53CG21/5f5uvgxnLwAAAMi7XNd/H3PMMeHGG2/M1o0/88wz2XryN73pTeGRRx4J++23X58fs3jx4j3WneddI3cSTlWOnrpTeF5KuEdSX70ANMsDAKCR5bqp2+62bNkSpk+fHj772c+GhQsX9jtDHt+6xRnyadOm5b6pW+ymnqJxGWma7+WlyVkKtXLzBQAAQqM3dett//33Dy9/+cvDunXr+n2fsWPHZm+1ptZmihtRNZvvNXJVhOZcAABQI2vIe9u6dWt47LHHwkEHHRTqVb01Lqsn1W6+Z39lAABobLmeIb/yyivDaaedlpWpP/300+Gaa64Jo0aNCuecc07qU6MBVbv5nqoIAABobLkO5L///e+z8L158+bQ1tYW3vjGN4Z77703+zvVK8OOM79K5NOVmSvhBgCAxlRTTd2GczF9o6lWt/BGk8fme26qAABAvpSbQwXyBlWtbuGNKg/N99xUAQCA2g7kNdXUjep2C+8dxnfvFk7+m+/FCod4U6W3eBxn8AEAgPwTyBtQtbuFM/LcVAEAgNonkDegancLp/wQvXzNxqpUILipAgAAtS/XXdaprW7h9B3Cf/t0Z/jGL54ID2z4Q8lGcINpzuamCgAA1D6BvAH0FfRiGNy9W3gM43Gc4Wm41tda79hAr5LmbKlvqujsDgAAQ6fLeh0rJ+jloVt4o3Sx78vyK48L19z6m4o63qfYgk1ndwAAGJhtzwb5RNQjW5ulEWePT/inu8t638VnHR6uuvnhkoF9oBslI3lTxfcUAAAMzLZnDU4X7nQGarjWW9MAj5fT8X6gLdiq1UzO9xQAAFSXNeR1qpwu3ErUh8dADdd6l6TPmzlx2DreV7u83PcUAABUl23P6pQu3Gl0Nzs7evoBWejuT3cDve7mbLu/bzyO40O5aRLDeFyb3lczuUr4ngIAgOoyQ16nUnfhbjR9zUYf0Dwm/KFrR8/x0TMOCO9/w4zwqqktRc//cHS87y4v3138XojjsXx9sN8DtfI9pQM8AAC1QiCvY7Y2G7nQ1tdsdOcf/5SF8L85fnbJrxPLx2M39Wo2Zxuu8vI8f0/pAA8AQK0RyOvYcAS9Wjccoa3UbPQDT/yhz+e9rxsC8c9qXZ/hKi/P8/dUqRL9UtvHAQBAKgJ5zgxHuW01g16tG47QNpjZ6JGaxR3u8vK8fU8NR4k+AAAMN03dciIGtbjHc9y/+vwlD4Tjr78rO+7otQaZkMttuwYzG13tRmulxJAfw3dveSkvr7ZybooAAEDemCHPCeW2w2+41lWXOxs90rO4eS4vrzYd4AEAqEVmyOt45paRC23lzEanmsWNIfz4uZPrNoxHw7l9HAAADBcz5HU8c1vrqr2efjjXVZczG20Wd3jluQM8AAD0RSDPAUGt2HA2Phvu0Faq2Vmt7ONdqxqpRB8AgPrQVCjsViddZzo7O0NLS0vo6OgIEyZMCHkVG7j1F9QG0/17OLq01+pzUUqq0Bab9O1+Q2A4uqwDAAD5z6ECeU4MNaiN1HZawy3eUIid5vuz/MrjavZGQ29mcQEAoH6VG8iVrNdJuW29dGlvlPX0edvHGwAAGHkCeR0EtUq308pjebv19AAAQKMQyOvAYGeV81zeXiuNz/J4MwMAAKgt9iGvA4OdVS5V3p4H5ezpnUq8mRGbzsV17ucveSAcf/1d2XHsAQAAADAYZsjrwGBmlQcqb1/x3xvDzkJIOvOb5+2r6mWtPgAAkJ5AXifK3V97oPL2c7/+QG7K2PPW+KzStfoAAAB9EcjrRLmzygOVt/f287XtVZ35rfV1143SAR4AABgZAnmdGWhWOZa3Hz3jgPDQhj+EXf9X3d6nXSFkM7+//v2W8JqD96/4nPLcRG4wdIAHAACqSVO3BtLdkOyBJwYO47393S0PD+nr5r2J3GDX6se1+b3F4zhudhwAABgMgbyB9BWM4zfA4S+bUPLjHvl/nVkp/FDWXfduNrf7uutakucO8AAAQG1Rst4g+mtIFsvSH/5/nWHO5HFh7cZtVV8fXW/rrvPcAR4AAKgtZsgbxEDB+Jx50we1l3mjr7uOIfz4uZOFcQAAoGICeYMYKBgff9jkbB30XsXLo4e8Ptq6awAAgL4J5DksLV++ZmPV11aXE4zjOug3zm6r+vpo664BAAD21FQo7NZtq850dnaGlpaW0NHRESZMKN28LKWR2Bqso2tH1tl8oK8xXOujrbsGAAAaQWeZOVQgz4m4HVnsgN67G3mcvY4z1LGJWDUJxgAAAOkDuS7rOe6A3ntrsGrOVMfPpTM4AABAWtaQ50A5W4MBAABQXwTyHKjXrcEAAADon0CeA7YGAwAAaDwCeU406tZgw7XNGwAAQN5p6pYTcdux2E09Tx3QY1iO69uH41xGYps3AACAPLPtGUnC8khu8wYAAJDHbc+UrLOHGMZjWO4tHi9atqqq27z1DuO7b/MGAABQ7wRyRjws2+YNAABAICdBWLbNGwAAgEBOgrBsmzcAAACBnERhuVG3eQMAAOimyzp76OjakTVwG4ktyfK0zRsAAMBIdlkXyHNqOPcAL5ewDAAAMHyBfHQFn5sc7QE+nME9fj6z1gAAAMNDIK+hPcCXLpxXcXAHAAAgX+xDXqN7gJcK7gAAAOSfQF6De4APJrgPVvzcy9ds7Pkcux/3NwYAAMDgKFmvwT3Aywnug1373VcJ/AHNY8Ifunb0HL/h0Ekh3gO45/HNPWPK5AEAACpjhrwG9wAvN7gPRl8l8L3DePSLxzYXhfFImTwAAEBlBPKciU3Z5s9uLRqLx3F8uPRXAl+OapTJAwAANCIl6zkTO6THbuql9gCvdsn6QJ+vHJWUyQMAADQygTynSu0BXu2S9YE+XzkqKZMHAABoZErW63it+VA/Xzkq/ZoAAACNTiCvUdVea97X54td1nuLXdaPnTWpal8TAACgkTUVChV08qohnZ2doaWlJXR0dIQJEyaEelNqrXk1Pl9fn7/aXxMAAKARc6hATi7ETu+xuZyQDwAANEog19SNpLZ0bc/2QI9bp3WLa9JjGXzsOA8AAFCvrCEnqRjGV67bVDQWjxctW5XsnAAAAEaCQE7VSs6Xr9mYrS8fzMfEmfGdu7UxiMdxfDCfCwAAoNYoWSdZyXlcM15KbBynaRwAAFCvzJCTrOR8+sTmko/HBm8AAAD1SiCnYkMtOZ/VNj6bTR/V1FQ0Ho/juNlxAACgngnkVKyckvOBxNL2+bNbi8bicRwHAACoZ9aQU7FqlJzHdeZLF87LZtNjgM/bPuT2RwcAAIaLQN4AeofKQqHQ8/ehBt/ukvO4Zrx32XosOY+z3IP5/PF98xTE7Y8OAAAMt6ZCTGh1rLOzM7S0tISOjo4wYcKE0Ej6CpW9ldsNvZSOrh1ZA7dKuqzn2blfu7/fGw1xRh8AAGCoOdQa8gbrgF5JN/RSCqH+7ufYHx0AABgJAnmd6i9UVtINfbi2PavnZnUAAAADEcjr1EChshoBs15nku2PDgAAjASBvE4NFCoH2w29kWaS7Y8OAACMBIG8TvUXKnuLjx0944AsOFcym13PM8n2RwcAAIabLut1rK8O6L0d0Dwm/KFrx5C6o1e7G3ne9v3O6/7oAABA7XdZF8jrVO9gG3WHyu6/f+nOdeGXT24ZcpCu1rZn9v0GAAAaLZCPHtGzYthni2OwvXDpg+GBJ/7Qb0COW88/sOH/Hu+rGVu5Xy9+zhjghzqTXKpbu32/AQCAeiSQ51Cls8Xx446//q6iMvRo5br2omBbTjO2wYbq+P6VlnR3d2uvxg0CAACAWqGpWw5Vurf3X33jwT3CeLSzEIq2IRuoGVssXV++ZuOIbVtWr93aAQAASjFDnjOVzhbHj3uwjzL0vma+uzuw796MLd6diTPw5379/iGtBx+seu7WDgAA0B8z5DlT6WzxQB+3e7Dta1uvGLo7/7hj0DPzQ2XfbwAAoBGZIc+ZSmeLB/q4uN9475n13ZuxxTL13jPjI72OO94g2L1be7xhEMcBAADqkUCeM/2Vk3dvSdZfKO7+uJ+vbQ+7+thv/F/OPbpkM7a4Zrzajd4GYzDd2vO2VzkAAEAlBPIcqnS2uK+PO3r6AeFf3n/0gGvA87KOu1S3dnuVAwAA9aSpEDelrmPlbsieR71ni+NlKndWuNI9wc/92v39zsznYS/wvJ8fAADAYHKoGfIci2E6lpsPdk/yvmaZyynzzvM6bnuVj8xzbCkAAACMHIG8hvckL2dWeDBl3oNZx53H7vN5OddaYykAAACkYduzHOueFe5dor175/OhBPr+xGB7/NzJuQq4eVnjXo8q+R4BAAAaJJB/8YtfDDNmzAj77LNPOOaYY8L99++5PVc9qnRP8moG+rywV/nwqKfvEQAAqDW5D+Tf+c53whVXXBGuueaa8Mtf/jIcccQR4eSTTw4bN5bepqseDHVWeKiBPm9imX1c095bXta416p6+x4BAIBakvs15J/97GfDhRdeGM4///zs+Ctf+Ur44Q9/GL7+9a+Hj370o6GeVboneb2Weed5jXutqrfvEQAAqCW5niHfvn17eOihh8JJJ53UM7bXXntlx/fcc0+fH/PSSy9lLeZ7v9WyocwK12uZdx7XuNeqev0eAQCAWpDrGfJNmzaFnTt3hgMPPLBoPB4/+uijfX7M4sWLw3XXXRfqxVBnhfO8lRn54HsEAADSyHUgr8RVV12VrTnvFmfIp02bFmpdX3uLl0OZN75HAAAgn3IdyFtbW8OoUaPCc889VzQej6dMmdLnx4wdOzZ7ozqBnsbhewQAAEZWrteQ77333uGoo44Kd9xxR8/Yrl27suNjjz026bkBAABA3c6QR7H8/P3vf3943eteF+bNmxc+97nPhW3btvV0XQcAAIBalPtA/u53vzu0t7eHj33sY+HZZ58Nr33ta8OPf/zjPRq9AQAAQC1pKhR6bXBdh2JTt5aWltDR0REmTJiQ+nQAAACoc51l5tBcryEHAACAeiWQAwAAQAICOQAAACQgkAMAAEACue+yzv94vH1r2PB8V5gxaVyY2TrO0wIAAFDjBPKc29K1PVy2bHVYsba9Z2zBnLZwwzlHhpbmMUnPDQAAgMopWc+5GMZXrttUNBaPFy1bleycAAAAGDqBPOdl6nFmfOduW8XH4zi+ftO2ZOcGAADA0AjkORbXjJfyxGaBHAAAoFYJ5Dk2fWJzycdjgzcAAABqk0CeY7PaxmcN3EY1NRWNx+M4rts6AABA7RLIcy52U58/u7VoLB7HcQAAAGqXbc9yLm5ttnThvKyBW1wzbh9yAACA+iCQ14hYnq5EHQAAoH4I5DW6HVrswG62HAAAoHYJ5DVkS9f2cNmy1dke5N1ic7e4njyWtgMAAFA7NHWrITGMr1y3qWgsHi9atirZOQEAAFAZgbyGytTjzPjOQqFoPB7H8dj0DQAAgNohkNeIuGa8lNiBvV5uPCxfs9ENBgAAoO5ZQ14jpk9sLvl4bPBWy6yPBwAAGo0Z8hoxq2181sBtVFNT0Xg8juO1viWa9fEAAECjEchrSOymPn92a9FYPI7jtcz6eAAAoBEpWa8hcWuzpQvnZeur45rxetmHvJz18fXw7wQAAOhNIK9BMZzWU0Ct9/XxAAAAfVGyTnL1vj4eAACgLwI5uVCv6+MBAAD6o2SdXKjX9fEAAAD9EcjJlXpbHw8AANAfJesAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJDA6BRflD093r41bHi+K8yYNC7MbB3nKQIAAKhzAnliW7q2h8uWrQ4r1rb3jC2Y0xZuOOfI0NI8Jum5AQAAMHyUrCcWw/jKdZuKxuLxomWrkp0TAAAAw08gT1ymHmfGdxYKRePxOI6v37Qt2bkBAAAwvATyhOKa8VKe2CyQAwAA1CuBPKHpE5tLPh4bvAEAAFCfBPKEZrWNzxq4jWpqKhqPx3Fct3UAAID6JZAnFrupz5/dWjQWj+M4AAAA9cu2Z4nFrc2WLpyXNXCLa8btQw4AANAYBPKciOXpStQBAAAah5J1AAAASEAgBwAAgAQEcgAAAEhAIAcAAIAEBHIAAABIQCAHAACABARyAAAASEAgBwAAgAQEcgAAAEhAIAcAAIAEBHIAAABIQCAHAACABARyAAAASEAgBwAAgAQEcgAAAEhAIAcAAIAEBHIAAABIQCAHAACABARyAAAASEAgBwAAgAQEcgAAAEhgdKhzhUIh+7OzszP1qQAAANAAOv83f3bn0YYN5C+88EL257Rp01KfCgAAAA3khRdeCC0tLf0+3lQYKLLXuF27doWnn3467LfffqGpqSnk9e5JvGHw1FNPhQkTJqQ+HYaRa904XOvG4Vo3Dte6cbjWjcO1bhydI5y5YsyOYXzq1Klhr732atwZ8viPP/jgg0MtiN8YAnljcK0bh2vdOFzrxuFaNw7XunG41o1jwghmrlIz4900dQMAAIAEBHIAAABIQCDPgbFjx4Zrrrkm+5P65lo3Dte6cbjWjcO1bhyudeNwrRvH2Jxmrrpv6gYAAAB5ZIYcAAAAEhDIAQAAIAGBHAAAABIQyAEAACABgXyYXXvttaGpqano7bDDDiv5MTfddFP2Pvvss084/PDDw49+9KPhPk2qYMaMGXtc6/h2ySWX9Pn+N9544x7vG685+bNixYpw2mmnhalTp2bX6Xvf+17R47E35sc+9rFw0EEHhX333TecdNJJYe3atQN+3i9+8YvZ90287sccc0y4//77h/FfwVCv9Y4dO8JHPvKR7OfyuHHjsvc599xzw9NPP1313wOkf12fd955e1y3t771rQN+Xq/r2rvWff3ujm+f+cxn+v2cXtf5tHjx4nD00UeH/fbbL0yePDmceeaZYc2aNUXv8+KLL2b/N5s0aVIYP358eMc73hGee+65kp+30t/zpLvWzz//fFi0aFGYO3duds0OOeSQcNlll4WOjo6Sn7fSn/1DIZCPgFe96lXhmWee6Xn7+c9/3u/7/uIXvwjnnHNOWLhwYVi1alX2zRXfHnnkkZE4VYbggQceKLrOP/nJT7Lxd77znf1+zIQJE4o+ZsOGDa5BDm3bti0cccQR2X+0+/LpT386fOELXwhf+cpXwn333ZeFtZNPPjn7pd+f73znO+GKK67Itt/45S9/mX3++DEbN24cxn8JQ7nWXV1d2bW6+uqrsz9vvvnm7Jf/6aefXtXfA+TjdR3F/4T1vm7Lli0r+Tm9rmvzWve+xvHt61//evaf8BjUSvG6zp+77747C9v33ntv9v+weCP1LW95S/Y90O2DH/xg+MEPfpBNgMX3jzdVzzrrrJKft5Lf86S91k8//XT2dv3112c5Kk6E/fjHP84y1kAG+7N/yOK2Zwyfa665pnDEEUeU/f7vete7Cm9729uKxo455pjCX//1Xw/D2TGc/vZv/7Zw6KGHFnbt2tXn40uWLCm0tLS4CDUm/ti85ZZbeo7j9Z0yZUrhM5/5TM/Yli1bCmPHji0sW7as388zb968wiWXXNJzvHPnzsLUqVMLixcvHsazZyjXui/3339/9n4bNmyo2u8B8nGt3//+9xfOOOOMQX0er+v6eF3H637CCSeUfB+v69qwcePG7JrffffdPb+fx4wZU7jpppt63ud3v/td9j733HNPn5+j0t/zpL3Wffnud79b2HvvvQs7duwo9KeSn/1DZYZ8BMSSllgmNWvWrPDe9743PPnkk/2+7z333JOVwfQW78DFcWrH9u3bw7/927+FCy64ILvL3p+tW7eG6dOnh2nTpoUzzjgj/OY3vxnR82To1q9fH5599tmi121LS0tWgt7f6zZ+fzz00ENFH7PXXntlx17rtSWWvsXX+P7771+13wPkx1133ZWVQsaSx4svvjhs3ry53/f1uq4PsXT5hz/8YVmzaF7X+dddnjxx4sTsz/i7N86k9v79G5cQxXLm/n7/VvJ7nvTXur/3idWpo0ePDtX62V8NAvkwiy/W7hKJL3/5y9mL+k1velN44YUX+nz/+II/8MADi8bicRyndsT1aVu2bMnWofQnvshjWdytt96ahfddu3aFN7zhDeH3v//9iJ4rQ9P92hzM63bTpk1h586dXus1LpYqxjXlcZlR/AVfrd8D5EMsWVy6dGm44447wqc+9amsPPKUU07JXrt98bquD9/4xjeyNakDlTB7Xedf/H/V5ZdfHubPnx9e/epXZ2Px9/Lee++9x03UUr+zK/k9T/pr3dfP6I9//OPhAx/4QKjmz/5qKH17gCGLF7Dba17zmuwHeJwR/e53v1vW3Vdq09e+9rXs2scZsf4ce+yx2Vu3GMZf8YpXhK9+9avZDwwgv+IMy7ve9a6s0U8M2aX4PVCbzj777J6/x0Z+8Xf4oYcems2cnHjiiUnPjeETb5THKpaBmqx6XedfXF8c1w7r2VH/LhngWnd2doa3ve1t4ZWvfGXWkDFvP/vNkI+weEfu5S9/eVi3bl2fj0+ZMmWPTo/xOI5TG2Jjtp/+9Kfhr/7qrwb1cWPGjAlHHnlkv98b5FP3a3Mwr9vW1tYwatQor/UaD+PxtR4byZSaHa/k9wD5FJcbxNduf9fN67r2/exnP8saNQ7293fkdZ0vl156abjtttvC8uXLw8EHH9wzHn8vx+UlsYqx3N/ZlfyeJ/217har0eKsd6x8ueWWW7L/b1fzZ381COQjLK4Zfuyxx7JtE/oSZ0xjiURv8T98vWdSybclS5Zk607inbjBiKUwDz/8cL/fG+TTzJkzs1/IvV+38U5s7MLa3+s2lssdddRRRR8Ty63isdd6bYTxuHY03niL2+ZU+/cA+RSXE8V1hP1dN6/r+qhuiz+bY0f2wfK6zodYtRQDWgxed955Z/Y7urd4fWMg6/37N96EiX09+vv9W8nvedJf6+7rFDuvx5/P3//+9yvaXnign/1VMaIt5BrQhz70ocJdd91VWL9+fWHlypWFk046qdDa2pp1Aoz+8i//svDRj3605/3j+4wePbpw/fXXZ10fYxfP2A3y4YcfTvivoFyxU/YhhxxS+MhHPrLHY7tf6+uuu65w++23Fx577LHCQw89VDj77LML++yzT+E3v/mNJzxnXnjhhcKqVauyt/hj87Of/Wz29+7O2p/85CcL+++/f+HWW28t/PrXv866c86cObPwxz/+sedzxI69N9xwQ8/xt7/97axD64033lj47W9/W/jABz6QfY5nn302yb+Rga/19u3bC6effnrh4IMPLqxevbrwzDPP9Ly99NJL/V7rgX4PkL9rHR+78sors67L8br99Kc/LfzZn/1ZYc6cOYUXX3yx53N4XdfHz/Coo6Oj0NzcXPjyl7/c5+fwuq4NF198cbaDTfyZ2/tndFdXV8/7XHTRRdn/1e68887Cgw8+WDj22GOzt97mzp1buPnmm3uOy/k9T76udUdHR7ZT1eGHH15Yt25d0fv86U9/6vNal/uzv9oE8mH27ne/u3DQQQdlLfZf9rKXZcfxm6Lbm9/85qy9/u4t+V/+8pdnH/OqV72q8MMf/nC4T5MqiQE7/rJfs2bNHo/tfq0vv/zy7BdCvM4HHnhg4dRTTy388pe/dC1yaPny5dl13f2t+3rGLVGuvvrq7DrGkH3iiSfu8T0wffr07AZbbzG0dX8PxO2S7r333hH9dzG4ax1/Off1WHyLH9fftR7o9wD5u9bxP3RvectbCm1tbdlN8XhNL7zwwj1umHld18fP8OirX/1qYd999822s+qL13Vt6O9ndNxqtlsM0X/zN39TOOCAA7KbMG9/+9uzkLb75+n9MeX8nidf13p5P6/7+BZ/n/f+PN0fU+7P/mpr+t8TAQAAAEaQNeQAAACQgEAOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAOzhuOOOC5dffnluPg8A1COBHABy5rzzzgtNTU3Z29577x1mz54d/uEf/iH86U9/Cnl11113Zee7ZcuWovGbb745fPzjH092XgCQZ6NTnwAAsKe3vvWtYcmSJeGll14KP/rRj8Ill1wSxowZE6666qqaeromTpyY+hQAILfMkANADo0dOzZMmTIlTJ8+PVx88cXhpJNOCt///vfDH/7wh3DuueeGAw44IDQ3N4dTTjklrF27tufjbrzxxrD//vuH733ve2HOnDlhn332CSeffHJ46qmnimbgzzzzzKKvF8vKY3l5f/71X/81vO51rwv77bdfdl7vec97wsaNG7PHnnjiiXD88cdnf4/nFWfK49foq2S93PO//fbbwyte8Yowfvz47ObEM888U5XnFQDyRCAHgBqw7777hu3bt2dB98EHH8zC+T333BMKhUI49dRTw44dO3ret6urK3ziE58IS5cuDStXrszKyM8+++whff34+WPp+a9+9ass7McQ3h26p02bFv7jP/4j+/uaNWuy8Pz5z3++z89T7vlff/312U2AFStWhCeffDJceeWVQzp/AMgjJesAkGMxsN5xxx3ZjHGcTY5hOIbsN7zhDdnj3/zmN7NAHMff+c53ZmMx3P7zP/9zOOaYY7Ljb3zjG9ls8/333x/mzZtX0XlccMEFPX+fNWtW+MIXvhCOPvrosHXr1mwWu7s0ffLkydkMd1/iTHgM4uWc/1e+8pVw6KGHZseXXnpptoYeAOqNGXIAyKHbbrstC7qx5DwG8Xe/+93Z7PLo0aN7gnY0adKkMHfu3PC73/2uZyy+TwzL3Q477LAsJPd+n8F66KGHwmmnnRYOOeSQrGz9zW9+czYeZ6/LFb9+OecfS9m7w3h00EEH9ZTHA0A9EcgBIIfimuzVq1dns8p//OMfs1nuuDa7Gvbaa69s5r233iXju9u2bVu2Dn3ChAnZjPYDDzwQbrnlluyxWEZfbbF5XW/x3737+QJAPRDIASCHxo0bl213Fmek46xyFMvO49Zn9913X8/7bd68OVu3/cpXvrJnLL5PXKfdLT4e15HHj4/a2tr2aJIWw39/Hn300ezrfPKTnwxvetObshn33Wes4/Zs0c6dO/v9POWePwA0CoEcAGpE7Jp+xhlnhAsvvDD8/Oc/zxqsve997wsve9nLsvHeM8yLFi3Kgm8sNY+l7q9//et71o+fcMIJWWCPTd/iDPw111wTHnnkkX6/brwpEAP3DTfcEB5//PFsHfjue4vHbvBxJjuW2re3t2dryys9fwBoFAI5ANSQuDf5UUcdFf78z/88HHvssVkpd9ynvHeZd1yD/ZGPfCTbmmz+/PnZWvTvfOc7PY/H8vOrr746fPjDH87Wmr/wwgvZVmT9iTPqcTuym266KZvJjjPlsQt6bzFUX3fddeGjH/1oOPDAA7NGbJWePwA0iqaCRVkAUDdicI77fscSdQAg38yQAwAAQAICOQAAACSgZB0AAAASMEMOAAAACQjkAAAAkIBADgAAAAkI5AAAAJCAQA4AAAAJCOQAAACQgEAOAAAACQjkAAAAkIBADgAAAGHk/X8CNWZEcR4fzwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's implement linear regression using gradient descent to minimize the cost function.  The equations implemented in the following code samples are detailed in \"ex1.pdf\" in the \"exercises\" folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we'll create a function to compute the cost of a given solution (characterized by the parameters theta). The cost function is the Mean Sqaured error in matrix form: \n",
        "\n",
        "$$ MSE(\\theta) = \\frac{1}{N}\\sum_n^N [ y_n-x_n^T*\\theta]^2 $$\n",
        "\n",
        "where $\\theta$ and $x_n$ are vectors\n",
        "\n",
        "__Hint__: Use the matrix form of the cost function and make use of numpy operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def computeCost(x, y, theta):\n",
        "    errors = np.dot(x, theta) - y\n",
        "    return np.mean(errors ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's add a column of ones to the training set so we can use a vectorized solution to computing the cost and gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.insert(0, 'Ones', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's do some variable initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set X (training data) and y (target variable)\n",
        "cols = data.shape[1]\n",
        "X = data.iloc[:,0:cols-1]\n",
        "y = data.iloc[:,cols-1:cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look to make sure X (training set) and y (target variable) look correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ones</th>\n",
              "      <th>Population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6.1101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.5277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>8.5186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5.8598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ones  Population\n",
              "0     1      6.1101\n",
              "1     1      5.5277\n",
              "2     1      8.5186\n",
              "3     1      7.0032\n",
              "4     1      5.8598"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.5920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.1302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.6620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.8540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.8233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Profit\n",
              "0  17.5920\n",
              "1   9.1302\n",
              "2  13.6620\n",
              "3  11.8540\n",
              "4   6.8233"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert X and Y to numpy array for better manipulation. Initiliaze Theta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.array(X.values)\n",
        "y = np.array(y.values).flatten()\n",
        "theta = np.array([0,0])\n",
        "theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a quick look at the shape of our matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((97, 2), (2,), (97,))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, theta.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's compute the cost for our initial solution (0 values for theta)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(64.14546775491135)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "computeCost(X, y, theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far so good.  Now we need to define a function to perform gradient descent on the parameters theta using the update rules. Write first a function that computes the gradient of a matrix and then use it in the gradientDescent function.\n",
        "\n",
        "The gradient descent formula is:\n",
        "\n",
        "$$\\theta^{t+1} = \\theta^{t} - \\alpha*\\nabla MSE(\\theta^{t})$$\n",
        "\n",
        "where $\\nabla MSE(\\theta^{t})$ is the gradient of the cost function at $\\theta^{t}$\n",
        "\n",
        "__Hint__: Use the matrix form of the gradient and make use of numpy operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gradient(y, tx, w):\n",
        "    \"\"\"Compute the gradient and current MSE loss.\"\"\"\n",
        "    e = tx.dot(w) - y\n",
        "    gradient = (2 / len(y)) * tx.T.dot(e)\n",
        "    loss = np.mean(e ** 2)\n",
        "    return gradient, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradientDescent(X, y, theta, alpha,max_iters):\n",
        "    \"\"\"Gradient descent algorithm.\"\"\"\n",
        "    # Define parameters to store w and loss\n",
        "    ws = [theta]\n",
        "    cost = np.zeros(max_iters)\n",
        "    for n_iter in range(max_iters):\n",
        "        # ***************************************************\n",
        "        # compute gradient and loss\n",
        "        # ***************************************************\n",
        "        gradient, loss = compute_gradient(y, X, theta)\n",
        "        # ***************************************************\n",
        "        # update theta by gradient\n",
        "        # ***************************************************\n",
        "        theta = theta - alpha * gradient\n",
        "        # store w and loss\n",
        "        ws.append(theta)\n",
        "        cost[n_iter] = loss\n",
        "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
        "              bi=n_iter, ti=max_iters - 1, l=loss, w0=theta[0], w1=theta[1]))\n",
        "\n",
        "    return theta, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize some additional variables - the learning rate alpha, and the number of iterations to perform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha = 0.01\n",
        "iters = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's run the gradient descent algorithm to fit our parameters theta to the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Descent(0/999): loss=64.14546775491135, w0=0.11678270103092776, w1=1.3065769949111339\n",
            "Gradient Descent(1/999): loss=33.53928474333491, w0=0.018001608779719652, w1=0.4668851404174774\n",
            "Gradient Descent(2/999): loss=20.815159503537956, w0=0.058230490259482466, w1=1.0103985192819032\n",
            "Gradient Descent(3/999): loss=15.518366960604682, w0=0.008955584732491174, w1=0.6624640652822504\n",
            "Gradient Descent(4/999): loss=13.306575069293501, w0=0.017447688470967036, w1=0.8890358067492414\n",
            "Gradient Descent(5/999): loss=12.376211646075982, w0=-0.011205651785773662, w1=0.7453450091050499\n",
            "Gradient Descent(6/999): loss=11.978169038728407, w0=-0.015836161825038074, w1=0.8402702714870819\n",
            "Gradient Descent(7/999): loss=11.801307545851571, w0=-0.03586548478321529, w1=0.7814054019591588\n",
            "Gradient Descent(8/999): loss=11.716395840326452, w0=-0.045887710034750014, w1=0.821645887286302\n",
            "Gradient Descent(9/999): loss=11.66975757040281, w0=-0.06227657702470252, w1=0.798007276351539\n",
            "Gradient Descent(10/999): loss=11.63909786844649, w0=-0.07447993992474639, w1=0.8155287856125966\n",
            "Gradient Descent(11/999): loss=11.615156054554554, w0=-0.08929867579215695, w1=0.8065154361246224\n",
            "Gradient Descent(12/999): loss=11.594085154771326, w0=-0.10235009435917986, w1=0.8145948887823524\n",
            "Gradient Descent(13/999): loss=11.57428676210951, w0=-0.11645901891079322, w1=0.811650294700878\n",
            "Gradient Descent(14/999): loss=11.555096407741408, w0=-0.129805218995654, w1=0.8158022520353793\n",
            "Gradient Descent(15/999): loss=11.536237534751159, w0=-0.14356207790797884, w1=0.8153725418897819\n",
            "Gradient Descent(16/999): loss=11.517594708120669, w0=-0.1569736726651363, w1=0.8178874980936855\n",
            "Gradient Descent(17/999): loss=11.499119418305693, w0=-0.17052746631980284, w1=0.8184966258951271\n",
            "Gradient Descent(18/999): loss=11.480790957069816, w0=-0.1839095913220601, w1=0.8203259705114382\n",
            "Gradient Descent(19/999): loss=11.462600167377461, w0=-0.19732261554827574, w1=0.8213609071086568\n",
            "Gradient Descent(20/999): loss=11.444542693942985, w0=-0.21063627680288674, w1=0.8228998372158082\n",
            "Gradient Descent(21/999): loss=11.42661617984241, w0=-0.2239348120701722, w1=0.8241060040160729\n",
            "Gradient Descent(22/999): loss=11.408819102107842, w0=-0.23716421822924796, w1=0.8255187039129652\n",
            "Gradient Descent(23/999): loss=11.391150288067553, w0=-0.25035958323751545, w1=0.8267904031447669\n",
            "Gradient Descent(24/999): loss=11.373608714431438, w0=-0.2634985771734507, w1=0.8281451065334089\n",
            "Gradient Descent(25/999): loss=11.356193423813906, w0=-0.27659587340488007, w1=0.8294384772326225\n",
            "Gradient Descent(26/999): loss=11.33890349003421, w0=-0.2896422966363097, w1=0.8307635647986901\n",
            "Gradient Descent(27/999): loss=11.321738003676492, w0=-0.3026440403935427, w1=0.8320604294011863\n",
            "Gradient Descent(28/999): loss=11.304696066064789, w0=-0.3155973923913, w1=0.8333677287388969\n",
            "Gradient Descent(29/999): loss=11.287776786733453, w0=-0.3285050233718192, w1=0.8346605768984672\n",
            "Gradient Descent(30/999): loss=11.27097928234944, w0=-0.3413654893809772, w1=0.8359550400503488\n",
            "Gradient Descent(31/999): loss=11.254302676237955, w0=-0.3541799972784866, w1=0.8372407917250402\n",
            "Gradient Descent(32/999): loss=11.237746098158803, w0=-0.3669480445483487, w1=0.8385245147143746\n",
            "Gradient Descent(33/999): loss=11.221308684187079, w0=-0.37967022932978095, w1=0.8398019296894985\n",
            "Gradient Descent(34/999): loss=11.204989576637416, w0=-0.3923464394298649, w1=0.8410758220203125\n",
            "Gradient Descent(35/999): loss=11.1887879240065, w0=-0.4049770194607667, w1=0.842344423965439\n",
            "Gradient Descent(36/999): loss=11.17270288092331, w0=-0.4175620186540873, w1=0.8436089020451878\n",
            "Gradient Descent(37/999): loss=11.156733608102838, w0=-0.4301016756282442, w1=0.8448685316272173\n",
            "Gradient Descent(38/999): loss=11.140879272301378, w0=-0.44259610597218685, w1=0.8461238067793512\n",
            "Gradient Descent(39/999): loss=11.125139046272665, w0=-0.4550455035929783, w1=0.8473744360516899\n",
            "Gradient Descent(40/999): loss=11.109512108724548, w0=-0.46745001095608246, w1=0.8486206341426101\n",
            "Gradient Descent(41/999): loss=11.093997644276083, w0=-0.4798098027155704, w1=0.8498622894543948\n",
            "Gradient Descent(42/999): loss=11.078594843414963, w0=-0.49212503182013057, w1=0.8510995005820563\n",
            "Gradient Descent(43/999): loss=11.063302902455254, w0=-0.5043958642497894, w1=0.8523322305607661\n",
            "Gradient Descent(44/999): loss=11.048121023495467, w0=-0.5166224566324606, w1=0.8535605296946278\n",
            "Gradient Descent(45/999): loss=11.033048414376907, w0=-0.5288049706729281, w1=0.8547843919497466\n",
            "Gradient Descent(46/999): loss=11.018084288642372, w0=-0.5409435638571726, w1=0.8560038475054581\n",
            "Gradient Descent(47/999): loss=11.003227865495084, w0=-0.553038395446602, w1=0.857218903107842\n",
            "Gradient Descent(48/999): loss=10.988478369757956, w0=-0.5650896226183295, w1=0.8584295805106527\n",
            "Gradient Descent(49/999): loss=10.973835031833165, w0=-0.5770974029560516, w1=0.8596358917014933\n",
            "Gradient Descent(50/999): loss=10.959297087661964, w0=-0.5890618928481196, w1=0.8608378548682327\n",
            "Gradient Descent(51/999): loss=10.944863778684843, w0=-0.6009832485233055, w1=0.8620354841094084\n",
            "Gradient Descent(52/999): loss=10.930534351801933, w0=-0.6128616253866306, w1=0.8632287960659379\n",
            "Gradient Descent(53/999): loss=10.916308059333717, w0=-0.6246971784507469, w1=0.8644178056474904\n",
            "Gradient Descent(54/999): loss=10.902184158982017, w0=-0.6364900620612519, w1=0.8656025287870628\n",
            "Gradient Descent(55/999): loss=10.888161913791253, w0=-0.6482404300770326, w1=0.8667829806660607\n",
            "Gradient Descent(56/999): loss=10.874240592110011, w0=-0.6599484357573425, w1=0.8679591768585191\n",
            "Gradient Descent(57/999): loss=10.860419467552845, w0=-0.6716142318378707, w1=0.8691311325940132\n",
            "Gradient Descent(58/999): loss=10.84669781896239, w0=-0.683237970484998, w1=0.8702988632330222\n",
            "Gradient Descent(59/999): loss=10.833074930371732, w0=-0.6948198033285465, w1=0.8714623839608986\n",
            "Gradient Descent(60/999): loss=10.819550090967038, w0=-0.7063598814439306, w1=0.872621709985424\n",
            "Gradient Descent(61/999): loss=10.806122595050482, w0=-0.7178583553669053, w1=0.8737768564098156\n",
            "Gradient Descent(62/999): loss=10.79279174200342, w0=-0.7293153750872957, w1=0.8749278383148955\n",
            "Gradient Descent(63/999): loss=10.77955683624983, w0=-0.7407310900562597, w1=0.8760746707064573\n",
            "Gradient Descent(64/999): loss=10.766417187220013, w0=-0.7521056491848177, w1=0.8772173685495103\n",
            "Gradient Descent(65/999): loss=10.753372109314563, w0=-0.7634392008479994, w1=0.878355946746532\n",
            "Gradient Descent(66/999): loss=10.740420921868619, w0=-0.7747318928853586, w1=0.8794904201518022\n",
            "Gradient Descent(67/999): loss=10.727562949116308, w0=-0.7859838726038171, w1=0.880620803562486\n",
            "Gradient Descent(68/999): loss=10.71479752015551, w0=-0.7971952867789963, w1=0.881747111724697\n",
            "Gradient Descent(69/999): loss=10.702123968912844, w0=-0.8083662816575122, w1=0.8828693593299077\n",
            "Gradient Descent(70/999): loss=10.689541634108926, w0=-0.8194970029586378, w1=0.8839875610175774\n",
            "Gradient Descent(71/999): loss=10.67704985922384, w0=-0.8305875958763618, w1=0.8851017313737736\n",
            "Gradient Descent(72/999): loss=10.664647992462907, w0=-0.841638205081181, w1=0.886211884932374\n",
            "Gradient Descent(73/999): loss=10.652335386722669, w0=-0.8526489747220533, w1=0.8873180361746038\n",
            "Gradient Descent(74/999): loss=10.640111399557108, w0=-0.863620048428235, w1=0.8884201995296448\n",
            "Gradient Descent(75/999): loss=10.627975393144158, w0=-0.8745515693111824, w1=0.8895183893745532\n",
            "Gradient Descent(76/999): loss=10.61592673425238, w0=-0.8854436799664005, w1=0.8906126200346213\n",
            "Gradient Descent(77/999): loss=10.603964794207966, w0=-0.8962965224753147, w1=0.8917029057834518\n",
            "Gradient Descent(78/999): loss=10.592088948861907, w0=-0.9071102384071167, w1=0.8927892608432169\n",
            "Gradient Descent(79/999): loss=10.58029857855743, w0=-0.9178849688206161, w1=0.8938716993847968\n",
            "Gradient Descent(80/999): loss=10.56859306809769, w0=-0.9286208542660772, w1=0.8949502355279948\n",
            "Gradient Descent(81/999): loss=10.556971806713634, w0=-0.9393180347870544, w1=0.8960248833417019\n",
            "Gradient Descent(82/999): loss=10.545434188032148, w0=-0.9499766499222179, w1=0.897095656844093\n",
            "Gradient Descent(83/999): loss=10.533979610044435, w0=-0.9605968387071743, w1=0.8981625700028019\n",
            "Gradient Descent(84/999): loss=10.522607475074572, w0=-0.9711787396762802, w1=0.8992256367351077\n",
            "Gradient Descent(85/999): loss=10.511317189748349, w0=-0.9817224908644494, w1=0.9002848709081145\n",
            "Gradient Descent(86/999): loss=10.500108164962299, w0=-0.9922282298089532, w1=0.9013402863389333\n",
            "Gradient Descent(87/999): loss=10.488979815852954, w0=-1.0026960935512148, w1=0.9023918967948615\n",
            "Gradient Descent(88/999): loss=10.477931561766336, w0=-1.013126218638597, w1=0.9034397159935625\n",
            "Gradient Descent(89/999): loss=10.466962826227666, w0=-1.0235187411261826, w1=0.9044837576032457\n",
            "Gradient Descent(90/999): loss=10.456073036911265, w0=-1.0338737965785503, w1=0.9055240352428428\n",
            "Gradient Descent(91/999): loss=10.445261625610708, w0=-1.0441915200715424, w1=0.906560562482188\n",
            "Gradient Descent(92/999): loss=10.434528028209174, w0=-1.054472046194027, w1=0.9075933528421921\n",
            "Gradient Descent(93/999): loss=10.42387168465, w0=-1.064715509049653, w1=0.9086224197950221\n",
            "Gradient Descent(94/999): loss=10.413292038907477, w0=-1.0749220422586006, w1=0.909647776764274\n",
            "Gradient Descent(95/999): loss=10.40278853895782, w0=-1.085091778959323, w1=0.9106694371251497\n",
            "Gradient Descent(96/999): loss=10.392360636750373, w0=-1.0952248518102847, w1=0.9116874142046306\n",
            "Gradient Descent(97/999): loss=10.382007788179019, w0=-1.10532139299169, w1=0.9127017212816524\n",
            "Gradient Descent(98/999): loss=10.371729453053772, w0=-1.115381534207209, w1=0.9137123715872769\n",
            "Gradient Descent(99/999): loss=10.361525095072608, w0=-1.1254054066856942, w1=0.9147193783048662\n",
            "Gradient Descent(100/999): loss=10.351394181793475, w0=-1.1353931411828935, w1=0.9157227545702529\n",
            "Gradient Descent(101/999): loss=10.341336184606519, w0=-1.1453448679831548, w1=0.9167225134719134\n",
            "Gradient Descent(102/999): loss=10.331350578706479, w0=-1.1552607169011262, w1=0.917718668051137\n",
            "Gradient Descent(103/999): loss=10.321436843065332, w0=-1.1651408172834492, w1=0.9187112313021968\n",
            "Gradient Descent(104/999): loss=10.311594460405088, w0=-1.1749852980104456, w1=0.9197002161725192\n",
            "Gradient Descent(105/999): loss=10.301822917170817, w0=-1.1847942874977992, w1=0.9206856355628522\n",
            "Gradient Descent(106/999): loss=10.292121703503827, w0=-1.1945679136982306, w1=0.9216675023274351\n",
            "Gradient Descent(107/999): loss=10.282490313215089, w0=-1.2043063041031663, w1=0.9226458292741637\n",
            "Gradient Descent(108/999): loss=10.272928243758805, w0=-1.2140095857444015, w1=0.9236206291647607\n",
            "Gradient Descent(109/999): loss=10.263434996206197, w0=-1.223677885195758, w1=0.9245919147149385\n",
            "Gradient Descent(110/999): loss=10.254010075219462, w0=-1.2333113285747341, w1=0.9255596985945685\n",
            "Gradient Descent(111/999): loss=10.24465298902594, w0=-1.2429100415441507, w1=0.9265239934278436\n",
            "Gradient Descent(112/999): loss=10.235363249392458, w0=-1.2524741493137903, w1=0.9274848117934449\n",
            "Gradient Descent(113/999): loss=10.226140371599822, w0=-1.2620037766420298, w1=0.9284421662247044\n",
            "Gradient Descent(114/999): loss=10.21698387441757, w0=-1.2714990478374681, w1=0.9293960692097692\n",
            "Gradient Descent(115/999): loss=10.207893280078835, w0=-1.2809600867605484, w1=0.9303465331917647\n",
            "Gradient Descent(116/999): loss=10.19886811425542, w0=-1.2903870168251728, w1=0.9312935705689555\n",
            "Gradient Descent(117/999): loss=10.189907906033053, w0=-1.2997799610003127, w1=0.9322371936949088\n",
            "Gradient Descent(118/999): loss=10.181012187886813, w0=-1.309139041811613, w1=0.9331774148786547\n",
            "Gradient Descent(119/999): loss=10.17218049565674, w0=-1.3184643813429897, w1=0.9341142463848466\n",
            "Gradient Descent(120/999): loss=10.163412368523602, w0=-1.3277561012382235, w1=0.935047700433922\n",
            "Gradient Descent(121/999): loss=10.154707348984875, w0=-1.3370143227025455, w1=0.9359777892022609\n",
            "Gradient Descent(122/999): loss=10.14606498283085, w0=-1.3462391665042188, w1=0.9369045248223453\n",
            "Gradient Descent(123/999): loss=10.137484819120935, w0=-1.355430752976114, w1=0.9378279193829172\n",
            "Gradient Descent(124/999): loss=10.12896641016014, w0=-1.3645892020172785, w1=0.9387479849291366\n",
            "Gradient Descent(125/999): loss=10.120509311475708, w0=-1.3737146330945005, w1=0.939664733462738\n",
            "Gradient Descent(126/999): loss=10.112113081793918, w0=-1.3828071652438676, w1=0.9405781769421877\n",
            "Gradient Descent(127/999): loss=10.103777283017072, w0=-1.3918669170723197, w1=0.9414883272828394\n",
            "Gradient Descent(128/999): loss=10.095501480200632, w0=-1.4008940067591957, w1=0.9423951963570893\n",
            "Gradient Descent(129/999): loss=10.08728524153051, w0=-1.4098885520577755, w1=0.9432987959945319\n",
            "Gradient Descent(130/999): loss=10.07912813830057, w0=-1.4188506702968158, w1=0.9441991379821134\n",
            "Gradient Descent(131/999): loss=10.071029744890227, w0=-1.4277804783820807, w1=0.9450962340642856\n",
            "Gradient Descent(132/999): loss=10.062989638742248, w0=-1.4366780927978664, w1=0.9459900959431597\n",
            "Gradient Descent(133/999): loss=10.055007400340724, w0=-1.4455436296085211, w1=0.9468807352786586\n",
            "Gradient Descent(134/999): loss=10.04708261318915, w0=-1.4543772044599588, w1=0.9477681636886686\n",
            "Gradient Descent(135/999): loss=10.039214863788711, w0=-1.4631789325811677, w1=0.9486523927491912\n",
            "Gradient Descent(136/999): loss=10.031403741616698, w0=-1.4719489287857135, w1=0.949533433994495\n",
            "Gradient Descent(137/999): loss=10.023648839105103, w0=-1.480687307473237, w1=0.9504112989172641\n",
            "Gradient Descent(138/999): loss=10.015949751619333, w0=-1.4893941826309463, w1=0.9512859989687503\n",
            "Gradient Descent(139/999): loss=10.008306077437112, w0=-1.4980696678351038, w1=0.9521575455589213\n",
            "Gradient Descent(140/999): loss=10.000717417727506, w0=-1.5067138762525076, w1=0.9530259500566092\n",
            "Gradient Descent(141/999): loss=9.993183376530133, w0=-1.515326920641968, w1=0.9538912237896596\n",
            "Gradient Descent(142/999): loss=9.98570356073448, w0=-1.523908913355778, w1=0.954753378045079\n",
            "Gradient Descent(143/999): loss=9.97827758005941, w0=-1.5324599663411793, w1=0.9556124240691822\n",
            "Gradient Descent(144/999): loss=9.970905047032781, w0=-1.5409801911418222, w1=0.9564683730677386\n",
            "Gradient Descent(145/999): loss=9.96358557697125, w0=-1.5494696988992205, w1=0.9573212362061191\n",
            "Gradient Descent(146/999): loss=9.956318787960175, w0=-1.557928600354202, w1=0.9581710246094405\n",
            "Gradient Descent(147/999): loss=9.94910430083371, w0=-1.5663570058483525, w1=0.9590177493627126\n",
            "Gradient Descent(148/999): loss=9.941941739155011, w0=-1.5747550253254547, w1=0.9598614215109803\n",
            "Gradient Descent(149/999): loss=9.934830729196591, w0=-1.5831227683329239, w1=0.9607020520594702\n",
            "Gradient Descent(150/999): loss=9.927770899920827, w0=-1.5914603440232349, w1=0.9615396519737319\n",
            "Gradient Descent(151/999): loss=9.920761882960596, w0=-1.5997678611553474, w1=0.9623742321797832\n",
            "Gradient Descent(152/999): loss=9.913803312600058, w0=-1.6080454280961245, w1=0.9632058035642502\n",
            "Gradient Descent(153/999): loss=9.906894825755565, w0=-1.6162931528217455, w1=0.964034376974512\n",
            "Gradient Descent(154/999): loss=9.900036061956728, w0=-1.6245111429191152, w1=0.9648599632188396\n",
            "Gradient Descent(155/999): loss=9.893226663327601, w0=-1.6326995055872668, w1=0.965682573066539\n",
            "Gradient Descent(156/999): loss=9.886466274568006, w0=-1.6408583476387606, w1=0.9665022172480904\n",
            "Gradient Descent(157/999): loss=9.879754542935007, w0=-1.648987775501077, w1=0.9673189064552885\n",
            "Gradient Descent(158/999): loss=9.87309111822448, w0=-1.6570878952180048, w1=0.9681326513413822\n",
            "Gradient Descent(159/999): loss=9.866475652752865, w0=-1.665158812451025, w1=0.9689434625212133\n",
            "Gradient Descent(160/999): loss=9.859907801339018, w0=-1.6732006324806887, w1=0.9697513505713552\n",
            "Gradient Descent(161/999): loss=9.853387221286187, w0=-1.68121346020799, w1=0.9705563260302505\n",
            "Gradient Descent(162/999): loss=9.846913572364146, w0=-1.689197400155735, w1=0.9713583993983489\n",
            "Gradient Descent(163/999): loss=9.840486516791442, w0=-1.6971525564699055, w1=0.9721575811382439\n",
            "Gradient Descent(164/999): loss=9.834105719217755, w0=-1.7050790329210164, w1=0.9729538816748093\n",
            "Gradient Descent(165/999): loss=9.827770846706418, w0=-1.7129769329054705, w1=0.9737473113953352\n",
            "Gradient Descent(166/999): loss=9.821481568717036, w0=-1.7208463594469063, w1=0.9745378806496638\n",
            "Gradient Descent(167/999): loss=9.81523755708824, w0=-1.7286874151975429, w1=0.9753255997503236\n",
            "Gradient Descent(168/999): loss=9.809038486020567, w0=-1.736500202439518, w1=0.9761104789726652\n",
            "Gradient Descent(169/999): loss=9.802884032059454, w0=-1.744284823086223, w1=0.9768925285549939\n",
            "Gradient Descent(170/999): loss=9.796773874078372, w0=-1.7520413786836313, w1=0.977671758698704\n",
            "Gradient Descent(171/999): loss=9.790707693262059, w0=-1.7597699704116245, w1=0.9784481795684128\n",
            "Gradient Descent(172/999): loss=9.784685173089885, w0=-1.7674706990853108, w1=0.9792218012920906\n",
            "Gradient Descent(173/999): loss=9.778705999319355, w0=-1.7751436651563408, w1=0.9799926339611958\n",
            "Gradient Descent(174/999): loss=9.772769859969687, w0=-1.7827889687142175, w1=0.9807606876308045\n",
            "Gradient Descent(175/999): loss=9.766876445305542, w0=-1.7904067094876022, w1=0.9815259723197424\n",
            "Gradient Descent(176/999): loss=9.761025447820879, w0=-1.797996986845615, w1=0.9822884980107156\n",
            "Gradient Descent(177/999): loss=9.755216562222888, w0=-1.8055598997991316, w1=0.9830482746504403\n",
            "Gradient Descent(178/999): loss=9.749449485416068, w0=-1.8130955470020744, w1=0.9838053121497734\n",
            "Gradient Descent(179/999): loss=9.743723916486417, w0=-1.8206040267526995, w1=0.9845596203838406\n",
            "Gradient Descent(180/999): loss=9.738039556685727, w0=-1.828085436994879, w1=0.9853112091921665\n",
            "Gradient Descent(181/999): loss=9.732396109415994, w0=-1.8355398753193783, w1=0.9860600883788018\n",
            "Gradient Descent(182/999): loss=9.726793280213943, w0=-1.8429674389651298, w1=0.9868062677124523\n",
            "Gradient Descent(183/999): loss=9.721230776735675, w0=-1.8503682248205007, w1=0.9875497569266051\n",
            "Gradient Descent(184/999): loss=9.71570830874139, w0=-1.857742329424557, w1=0.9882905657196567\n",
            "Gradient Descent(185/999): loss=9.71022558808026, w0=-1.8650898489683232, w1=0.9890287037550387\n",
            "Gradient Descent(186/999): loss=9.70478232867539, w0=-1.8724108792960361, w1=0.9897641806613448\n",
            "Gradient Descent(187/999): loss=9.699378246508896, w0=-1.8797055159063965, w1=0.9904970060324546\n",
            "Gradient Descent(188/999): loss=9.694013059607073, w0=-1.8869738539538132, w1=0.9912271894276611\n",
            "Gradient Descent(189/999): loss=9.688686488025692, w0=-1.8942159882496457, w1=0.9919547403717937\n",
            "Gradient Descent(190/999): loss=9.683398253835389, w0=-1.9014320132634401, w1=0.9926796683553427\n",
            "Gradient Descent(191/999): loss=9.678148081107171, w0=-1.908622023124162, w1=0.9934019828345843\n",
            "Gradient Descent(192/999): loss=9.672935695898005, w0=-1.9157861116214236, w1=0.9941216932317016\n",
            "Gradient Descent(193/999): loss=9.667760826236538, w0=-1.9229243722067082, w1=0.9948388089349103\n",
            "Gradient Descent(194/999): loss=9.662623202108898, w0=-1.9300368979945879, w1=0.9955533392985791\n",
            "Gradient Descent(195/999): loss=9.657522555444597, w0=-1.9371237817639393, w1=0.9962652936433523\n",
            "Gradient Descent(196/999): loss=9.652458620102571, w0=-1.9441851159591532, w1=0.9969746812562719\n",
            "Gradient Descent(197/999): loss=9.647431131857266, w0=-1.9512209926913409, w1=0.9976815113908979\n",
            "Gradient Descent(198/999): loss=9.642439828384862, w0=-1.9582315037395353, w1=0.9983857932674298\n",
            "Gradient Descent(199/999): loss=9.637484449249586, w0=-1.965216740551888, w1=0.9990875360728265\n",
            "Gradient Descent(200/999): loss=9.632564735890117, w0=-1.9721767942468635, w1=0.9997867489609258\n",
            "Gradient Descent(201/999): loss=9.62768043160611, w0=-1.9791117556144258, w1=1.0004834410525647\n",
            "Gradient Descent(202/999): loss=9.622831281544782, w0=-1.9860217151172237, w1=1.001177621435697\n",
            "Gradient Descent(203/999): loss=9.618017032687629, w0=-1.9929067628917714, w1=1.001869299165514\n",
            "Gradient Descent(204/999): loss=9.613237433837213, w0=-1.9997669887496234, w1=1.0025584832645598\n",
            "Gradient Descent(205/999): loss=9.608492235604071, w0=-2.0066024821785464, w1=1.0032451827228517\n",
            "Gradient Descent(206/999): loss=9.603781190393683, w0=-2.0134133323436862, w1=1.0039294064979956\n",
            "Gradient Descent(207/999): loss=9.59910405239356, w0=-2.0201996280887315, w1=1.0046111635153032\n",
            "Gradient Descent(208/999): loss=9.594460577560435, w0=-2.0269614579370727, w1=1.0052904626679104\n",
            "Gradient Descent(209/999): loss=9.589850523607499, w0=-2.033698910092956, w1=1.0059673128168891\n",
            "Gradient Descent(210/999): loss=9.585273649991786, w0=-2.040412072442634, w1=1.006641722791368\n",
            "Gradient Descent(211/999): loss=9.580729717901598, w0=-2.0471010325555135, w1=1.0073137013886428\n",
            "Gradient Descent(212/999): loss=9.576218490244068, w0=-2.0537658776852963, w1=1.007983257374295\n",
            "Gradient Descent(213/999): loss=9.571739731632777, w0=-2.060406694771118, w1=1.0086503994823033\n",
            "Gradient Descent(214/999): loss=9.567293208375467, w0=-2.067023570438682, w1=1.0093151364151594\n",
            "Gradient Descent(215/999): loss=9.562878688461858, w0=-2.0736165910013886, w1=1.0099774768439806\n",
            "Gradient Descent(216/999): loss=9.558495941551536, w0=-2.0801858424614634, w1=1.0106374294086233\n",
            "Gradient Descent(217/999): loss=9.554144738961934, w0=-2.086731410511076, w1=1.0112950027177954\n",
            "Gradient Descent(218/999): loss=9.549824853656403, w0=-2.09325338053346, w1=1.011950205349169\n",
            "Gradient Descent(219/999): loss=9.545536060232369, w0=-2.099751837604026, w1=1.0126030458494915\n",
            "Gradient Descent(220/999): loss=9.54127813490956, w0=-2.1062268664914714, w1=1.0132535327346985\n",
            "Gradient Descent(221/999): loss=9.537050855518341, w0=-2.112678551658886, w1=1.013901674490023\n",
            "Gradient Descent(222/999): loss=9.532854001488117, w0=-2.1191069772648543, w1=1.0145474795701084\n",
            "Gradient Descent(223/999): loss=9.528687353835823, w0=-2.125512227164553, w1=1.0151909563991162\n",
            "Gradient Descent(224/999): loss=9.5245506951545, w0=-2.1318943849108445, w1=1.0158321133708377\n",
            "Gradient Descent(225/999): loss=9.520443809601959, w0=-2.138253533755367, w1=1.0164709588488035\n",
            "Gradient Descent(226/999): loss=9.516366482889495, w0=-2.1445897566496215, w1=1.0171075011663906\n",
            "Gradient Descent(227/999): loss=9.512318502270734, w0=-2.1509031362460513, w1=1.017741748626935\n",
            "Gradient Descent(228/999): loss=9.508299656530514, w0=-2.1571937548991236, w1=1.0183737095038343\n",
            "Gradient Descent(229/999): loss=9.504309735973875, w0=-2.163461694666401, w1=1.0190033920406625\n",
            "Gradient Descent(230/999): loss=9.500348532415103, w0=-2.1697070373096135, w1=1.0196308044512712\n",
            "Gradient Descent(231/999): loss=9.496415839166886, w0=-2.175929864295723, w1=1.0202559549199006\n",
            "Gradient Descent(232/999): loss=9.492511451029522, w0=-2.182130256797989, w1=1.0208788516012852\n",
            "Gradient Descent(233/999): loss=9.4886351642802, w0=-2.188308295697025, w1=1.02149950262076\n",
            "Gradient Descent(234/999): loss=9.484786776662386, w0=-2.194464061581854, w1=1.022117916074366\n",
            "Gradient Descent(235/999): loss=9.480966087375268, w0=-2.2005976347509613, w1=1.022734100028958\n",
            "Gradient Descent(236/999): loss=9.477172897063275, w0=-2.20670909521334, w1=1.0233480625223061\n",
            "Gradient Descent(237/999): loss=9.473407007805664, w0=-2.2127985226895355, w1=1.0239598115632047\n",
            "Gradient Descent(238/999): loss=9.469668223106215, w0=-2.218865996612686, w1=1.024569355131573\n",
            "Gradient Descent(239/999): loss=9.465956347882965, w0=-2.2249115961295565, w1=1.0251767011785637\n",
            "Gradient Descent(240/999): loss=9.46227118845803, w0=-2.230935400101574, w1=1.0257818576266609\n",
            "Gradient Descent(241/999): loss=9.458612552547503, w0=-2.2369374871058554, w1=1.0263848323697895\n",
            "Gradient Descent(242/999): loss=9.454980249251408, w0=-2.2429179354362305, w1=1.0269856332734129\n",
            "Gradient Descent(243/999): loss=9.451374089043764, w0=-2.248876823104266, w1=1.0275842681746403\n",
            "Gradient Descent(244/999): loss=9.447793883762673, w0=-2.2548142278402814, w1=1.0281807448823241\n",
            "Gradient Descent(245/999): loss=9.444239446600516, w0=-2.260730227094364, w1=1.028775071177167\n",
            "Gradient Descent(246/999): loss=9.440710592094193, w0=-2.2666248980373775, w1=1.0293672548118185\n",
            "Gradient Descent(247/999): loss=9.437207136115466, w0=-2.2724983175619715, w1=1.0299573035109795\n",
            "Gradient Descent(248/999): loss=9.433728895861321, w0=-2.278350562283582, w1=1.0305452249715015\n",
            "Gradient Descent(249/999): loss=9.430275689844464, w0=-2.2841817085414315, w1=1.0311310268624874\n",
            "Gradient Descent(250/999): loss=9.42684733788383, w0=-2.2899918323995254, w1=1.031714716825392\n",
            "Gradient Descent(251/999): loss=9.423443661095181, w0=-2.295781009647644, w1=1.03229630247412\n",
            "Gradient Descent(252/999): loss=9.42006448188179, w0=-2.3015493158023297, w1=1.032875791395128\n",
            "Gradient Descent(253/999): loss=9.416709623925145, w0=-2.3072968261078746, w1=1.033453191147521\n",
            "Gradient Descent(254/999): loss=9.413378912175784, w0=-2.3130236155373, w1=1.0340285092631525\n",
            "Gradient Descent(255/999): loss=9.410072172844133, w0=-2.3187297587933355, w1=1.0346017532467213\n",
            "Gradient Descent(256/999): loss=9.40678923339145, w0=-2.324415330309393, w1=1.0351729305758715\n",
            "Gradient Descent(257/999): loss=9.403529922520825, w0=-2.330080404250537, w1=1.0357420487012883\n",
            "Gradient Descent(258/999): loss=9.400294070168234, w0=-2.335725054514454, w1=1.0363091150467953\n",
            "Gradient Descent(259/999): loss=9.397081507493668, w0=-2.341349354732414, w1=1.0368741370094532\n",
            "Gradient Descent(260/999): loss=9.393892066872331, w0=-2.3469533782702325, w1=1.037437121959653\n",
            "Gradient Descent(261/999): loss=9.390725581885881, w0=-2.3525371982292276, w1=1.0379980772412158\n",
            "Gradient Descent(262/999): loss=9.38758188731376, w0=-2.3581008874471725, w1=1.0385570101714854\n",
            "Gradient Descent(263/999): loss=9.384460819124554, w0=-2.363644518499247, w1=1.0391139280414259\n",
            "Gradient Descent(264/999): loss=9.38136221446746, w0=-2.3691681636989825, w1=1.0396688381157164\n",
            "Gradient Descent(265/999): loss=9.378285911663772, w0=-2.3746718950992074, w1=1.0402217476328444\n",
            "Gradient Descent(266/999): loss=9.375231750198434, w0=-2.380155784492985, w1=1.0407726638052022\n",
            "Gradient Descent(267/999): loss=9.372199570711702, w0=-2.3856199034145513, w1=1.0413215938191798\n",
            "Gradient Descent(268/999): loss=9.36918921499079, w0=-2.3910643231402475, w1=1.0418685448352583\n",
            "Gradient Descent(269/999): loss=9.366200525961629, w0=-2.3964891146894494, w1=1.0424135239881052\n",
            "Gradient Descent(270/999): loss=9.363233347680683, w0=-2.401894348825495, w1=1.0429565383866641\n",
            "Gradient Descent(271/999): loss=9.360287525326797, w0=-2.4072800960566076, w1=1.0434975951142524\n",
            "Gradient Descent(272/999): loss=9.357362905193117, w0=-2.412646426636813, w1=1.0440367012286473\n",
            "Gradient Descent(273/999): loss=9.35445933467909, w0=-2.4179934105668592, w1=1.044573863762185\n",
            "Gradient Descent(274/999): loss=9.351576662282477, w0=-2.423321117595128, w1=1.0451090897218454\n",
            "Gradient Descent(275/999): loss=9.348714737591461, w0=-2.4286296172185438, w1=1.0456423860893496\n",
            "Gradient Descent(276/999): loss=9.345873411276806, w0=-2.4339189786834825, w1=1.0461737598212464\n",
            "Gradient Descent(277/999): loss=9.343052535084041, w0=-2.439189270986673, w1=1.0467032178490057\n",
            "Gradient Descent(278/999): loss=9.340251961825754, w0=-2.444440562876098, w1=1.0472307670791086\n",
            "Gradient Descent(279/999): loss=9.337471545373882, w0=-2.44967292285189, w1=1.0477564143931357\n",
            "Gradient Descent(280/999): loss=9.334711140652121, w0=-2.454886419167227, w1=1.0482801666478594\n",
            "Gradient Descent(281/999): loss=9.331970603628324, w0=-2.4600811198292187, w1=1.0488020306753318\n",
            "Gradient Descent(282/999): loss=9.329249791307001, w0=-2.465257092599798, w1=1.0493220132829735\n",
            "Gradient Descent(283/999): loss=9.326548561721854, w0=-2.4704144049966024, w1=1.049840121253664\n",
            "Gradient Descent(284/999): loss=9.32386677392838, w0=-2.4755531242938553, w1=1.0503563613458284\n",
            "Gradient Descent(285/999): loss=9.3212042879965, w0=-2.480673317523244, w1=1.0508707402935273\n",
            "Gradient Descent(286/999): loss=9.318560965003265, w0=-2.4857750514747936, w1=1.0513832648065424\n",
            "Gradient Descent(287/999): loss=9.315936667025618, w0=-2.4908583926977386, w1=1.051893941570467\n",
            "Gradient Descent(288/999): loss=9.313331257133173, w0=-2.49592340750139, w1=1.0524027772467899\n",
            "Gradient Descent(289/999): loss=9.310744599381097, w0=-2.500970161956001, w1=1.052909778472985\n",
            "Gradient Descent(290/999): loss=9.308176558802996, w0=-2.5059987218936306, w1=1.0534149518625968\n",
            "Gradient Descent(291/999): loss=9.30562700140389, w0=-2.5110091529089984, w1=1.0539183040053264\n",
            "Gradient Descent(292/999): loss=9.3030957941532, w0=-2.516001520360344, w1=1.0544198414671175\n",
            "Gradient Descent(293/999): loss=9.300582804977836, w0=-2.520975889370277, w1=1.054919570790243\n",
            "Gradient Descent(294/999): loss=9.298087902755277, w0=-2.525932324826628, w1=1.0554174984933893\n",
            "Gradient Descent(295/999): loss=9.295610957306737, w0=-2.5308708913832945, w1=1.0559136310717412\n",
            "Gradient Descent(296/999): loss=9.293151839390394, w0=-2.5357916534610845, w1=1.0564079749970685\n",
            "Gradient Descent(297/999): loss=9.290710420694614, w0=-2.5406946752485564, w1=1.0569005367178073\n",
            "Gradient Descent(298/999): loss=9.28828657383128, w0=-2.545580020702857, w1=1.0573913226591471\n",
            "Gradient Descent(299/999): loss=9.285880172329131, w0=-2.550447753550554, w1=1.057880339223113\n",
            "Gradient Descent(300/999): loss=9.283491090627168, w0=-2.5552979372884703, w1=1.0583675927886493\n",
            "Gradient Descent(301/999): loss=9.281119204068114, w0=-2.5601306351845095, w1=1.0588530897117034\n",
            "Gradient Descent(302/999): loss=9.278764388891883, w0=-2.5649459102784826, w1=1.059336836325308\n",
            "Gradient Descent(303/999): loss=9.276426522229148, w0=-2.56974382538293, w1=1.0598188389396639\n",
            "Gradient Descent(304/999): loss=9.274105482094916, w0=-2.574524443083941, w1=1.060299103842223\n",
            "Gradient Descent(305/999): loss=9.271801147382172, w0=-2.57928782574197, w1=1.060777637297769\n",
            "Gradient Descent(306/999): loss=9.269513397855548, w0=-2.584034035492649, w1=1.0612544455485005\n",
            "Gradient Descent(307/999): loss=9.267242114145057, w0=-2.5887631342476016, w1=1.0617295348141111\n",
            "Gradient Descent(308/999): loss=9.264987177739872, w0=-2.5934751836952454, w1=1.062202911291872\n",
            "Gradient Descent(309/999): loss=9.26274847098213, w0=-2.598170245301601, w1=1.0626745811567115\n",
            "Gradient Descent(310/999): loss=9.260525877060788, w0=-2.602848380311092, w1=1.063144550561296\n",
            "Gradient Descent(311/999): loss=9.25831928000555, w0=-2.6075096497473433, w1=1.0636128256361113\n",
            "Gradient Descent(312/999): loss=9.256128564680795, w0=-2.6121541144139795, w1=1.0640794124895399\n",
            "Gradient Descent(313/999): loss=9.253953616779587, w0=-2.616781834895415, w1=1.064544317207944\n",
            "Gradient Descent(314/999): loss=9.251794322817686, w0=-2.6213928715576467, w1=1.065007545855743\n",
            "Gradient Descent(315/999): loss=9.24965057012765, w0=-2.6259872845490397, w1=1.0654691044754923\n",
            "Gradient Descent(316/999): loss=9.247522246852958, w0=-2.6305651338011136, w1=1.065928999087963\n",
            "Gradient Descent(317/999): loss=9.245409241942147, w0=-2.6351264790293225, w1=1.0663872356922202\n",
            "Gradient Descent(318/999): loss=9.243311445143041, w0=-2.639671379733836, w1=1.0668438202657018\n",
            "Gradient Descent(319/999): loss=9.241228746996994, w0=-2.6441998952003125, w1=1.0672987587642944\n",
            "Gradient Descent(320/999): loss=9.23916103883317, w0=-2.6487120845006764, w1=1.0677520571224144\n",
            "Gradient Descent(321/999): loss=9.23710821276289, w0=-2.6532080064938848, w1=1.068203721253082\n",
            "Gradient Descent(322/999): loss=9.235070161673974, w0=-2.657687719826697, w1=1.0686537570480004\n",
            "Gradient Descent(323/999): loss=9.233046779225186, w0=-2.662151282934441, w1=1.069102170377632\n",
            "Gradient Descent(324/999): loss=9.231037959840663, w0=-2.666598754041772, w1=1.0695489670912752\n",
            "Gradient Descent(325/999): loss=9.229043598704408, w0=-2.6710301911634367, w1=1.0699941530171404\n",
            "Gradient Descent(326/999): loss=9.227063591754835, w0=-2.6754456521050254, w1=1.0704377339624265\n",
            "Gradient Descent(327/999): loss=9.225097835679316, w0=-2.6798451944637294, w1=1.0708797157133958\n",
            "Gradient Descent(328/999): loss=9.223146227908819, w0=-2.68422887562909, w1=1.07132010403545\n",
            "Gradient Descent(329/999): loss=9.22120866661253, w0=-2.68859675278375, w1=1.0717589046732063\n",
            "Gradient Descent(330/999): loss=9.219285050692552, w0=-2.692948882904196, w1=1.0721961233505706\n",
            "Gradient Descent(331/999): loss=9.21737527977863, w0=-2.6972853227615037, w1=1.072631765770813\n",
            "Gradient Descent(332/999): loss=9.215479254222917, w0=-2.701606128922079, w1=1.073065837616643\n",
            "Gradient Descent(333/999): loss=9.213596875094764, w0=-2.7059113577483953, w1=1.0734983445502821\n",
            "Gradient Descent(334/999): loss=9.211728044175567, w0=-2.7102010653997275, w1=1.0739292922135388\n",
            "Gradient Descent(335/999): loss=9.209872663953634, w0=-2.7144753078328856, w1=1.0743586862278813\n",
            "Gradient Descent(336/999): loss=9.208030637619112, w0=-2.7187341408029453, w1=1.074786532194512\n",
            "Gradient Descent(337/999): loss=9.206201869058916, w0=-2.722977619863974, w1=1.0752128356944395\n",
            "Gradient Descent(338/999): loss=9.204386262851731, w0=-2.7272058003697563, w1=1.0756376022885519\n",
            "Gradient Descent(339/999): loss=9.202583724263024, w0=-2.731418737474516, w1=1.0760608375176888\n",
            "Gradient Descent(340/999): loss=9.200794159240099, w0=-2.7356164861336345, w1=1.0764825469027153\n",
            "Gradient Descent(341/999): loss=9.199017474407196, w0=-2.7397991011043694, w1=1.0769027359445908\n",
            "Gradient Descent(342/999): loss=9.197253577060625, w0=-2.743966636946568, w1=1.0773214101244446\n",
            "Gradient Descent(343/999): loss=9.195502375163905, w0=-2.7481191480233775, w1=1.0777385749036439\n",
            "Gradient Descent(344/999): loss=9.193763777342985, w0=-2.7522566885019573, w1=1.0781542357238678\n",
            "Gradient Descent(345/999): loss=9.192037692881472, w0=-2.7563793123541824, w1=1.0785683980071765\n",
            "Gradient Descent(346/999): loss=9.190324031715885, w0=-2.7604870733573503, w1=1.0789810671560827\n",
            "Gradient Descent(347/999): loss=9.188622704430973, w0=-2.7645800250948795, w1=1.079392248553622\n",
            "Gradient Descent(348/999): loss=9.186933622255037, w0=-2.768658220957011, w1=1.0798019475634235\n",
            "Gradient Descent(349/999): loss=9.1852566970553, w0=-2.7727217141415035, w1=1.0802101695297788\n",
            "Gradient Descent(350/999): loss=9.183591841333314, w0=-2.7767705576543276, w1=1.0806169197777127\n",
            "Gradient Descent(351/999): loss=9.181938968220393, w0=-2.780804804310357, w1=1.0810222036130517\n",
            "Gradient Descent(352/999): loss=9.180297991473072, w0=-2.7848245067340573, w1=1.0814260263224953\n",
            "Gradient Descent(353/999): loss=9.178668825468622, w0=-2.788829717360174, w1=1.0818283931736812\n",
            "Gradient Descent(354/999): loss=9.177051385200562, w0=-2.792820488434415, w1=1.0822293094152582\n",
            "Gradient Descent(355/999): loss=9.175445586274252, w0=-2.796796872014131, w1=1.0826287802769516\n",
            "Gradient Descent(356/999): loss=9.173851344902452, w0=-2.800758919968998, w1=1.083026810969633\n",
            "Gradient Descent(357/999): loss=9.172268577900994, w0=-2.8047066839816903, w1=1.0834234066853876\n",
            "Gradient Descent(358/999): loss=9.170697202684396, w0=-2.8086402155485573, w1=1.0838185725975824\n",
            "Gradient Descent(359/999): loss=9.169137137261593, w0=-2.8125595659802936, w1=1.084212313860933\n",
            "Gradient Descent(360/999): loss=9.167588300231637, w0=-2.8164647864026087, w1=1.0846046356115715\n",
            "Gradient Descent(361/999): loss=9.166050610779443, w0=-2.8203559277568946, w1=1.0849955429671136\n",
            "Gradient Descent(362/999): loss=9.164523988671602, w0=-2.8242330408008898, w1=1.0853850410267243\n",
            "Gradient Descent(363/999): loss=9.163008354252161, w0=-2.8280961761093413, w1=1.0857731348711859\n",
            "Gradient Descent(364/999): loss=9.161503628438483, w0=-2.8319453840746647, w1=1.0861598295629624\n",
            "Gradient Descent(365/999): loss=9.160009732717132, w0=-2.835780714907601, w1=1.0865451301462685\n",
            "Gradient Descent(366/999): loss=9.158526589139749, w0=-2.8396022186378715, w1=1.0869290416471313\n",
            "Gradient Descent(367/999): loss=9.157054120319003, w0=-2.8434099451148316, w1=1.08731156907346\n",
            "Gradient Descent(368/999): loss=9.155592249424558, w0=-2.8472039440081196, w1=1.087692717415108\n",
            "Gradient Descent(369/999): loss=9.15414090017904, w0=-2.8509842648083055, w1=1.0880724916439404\n",
            "Gradient Descent(370/999): loss=9.15269999685409, w0=-2.854750956827536, w1=1.0884508967138966\n",
            "Gradient Descent(371/999): loss=9.151269464266383, w0=-2.8585040692001784, w1=1.0888279375610574\n",
            "Gradient Descent(372/999): loss=9.14984922777372, w0=-2.862243650883461, w1=1.0892036191037067\n",
            "Gradient Descent(373/999): loss=9.148439213271132, w0=-2.8659697506581128, w1=1.0895779462423985\n",
            "Gradient Descent(374/999): loss=9.147039347187018, w0=-2.869682417128997, w1=1.089950923860018\n",
            "Gradient Descent(375/999): loss=9.145649556479288, w0=-2.873381698725749, w1=1.0903225568218478\n",
            "Gradient Descent(376/999): loss=9.144269768631567, w0=-2.8770676437034046, w1=1.0906928499756294\n",
            "Gradient Descent(377/999): loss=9.14289991164942, w0=-2.8807403001430316, w1=1.0910618081516277\n",
            "Gradient Descent(378/999): loss=9.141539914056573, w0=-2.8843997159523562, w1=1.0914294361626935\n",
            "Gradient Descent(379/999): loss=9.140189704891194, w0=-2.888045938866388, w1=1.091795738804326\n",
            "Gradient Descent(380/999): loss=9.138849213702194, w0=-2.8916790164480433, w1=1.0921607208547364\n",
            "Gradient Descent(381/999): loss=9.13751837054555, w0=-2.8952989960887643, w1=1.0925243870749088\n",
            "Gradient Descent(382/999): loss=9.136197105980647, w0=-2.898905925009138, w1=1.0928867422086637\n",
            "Gradient Descent(383/999): loss=9.134885351066664, w0=-2.9024998502595123, w1=1.0932477909827187\n",
            "Gradient Descent(384/999): loss=9.133583037358976, w0=-2.90608081872061, w1=1.0936075381067507\n",
            "Gradient Descent(385/999): loss=9.132290096905576, w0=-2.9096488771041393, w1=1.0939659882734583\n",
            "Gradient Descent(386/999): loss=9.131006462243537, w0=-2.913204071953404, w1=1.0943231461586196\n",
            "Gradient Descent(387/999): loss=9.12973206639549, w0=-2.9167464496439104, w1=1.094679016421159\n",
            "Gradient Descent(388/999): loss=9.128466842866123, w0=-2.920276056383972, w1=1.0950336037032018\n",
            "Gradient Descent(389/999): loss=9.127210725638717, w0=-2.9237929382153123, w1=1.095386912630139\n",
            "Gradient Descent(390/999): loss=9.125963649171707, w0=-2.9272971410136663, w1=1.0957389478106851\n",
            "Gradient Descent(391/999): loss=9.124725548395249, w0=-2.9307887104893777, w1=1.0960897138369408\n",
            "Gradient Descent(392/999): loss=9.123496358707834, w0=-2.9342676921879955, w1=1.09643921528445\n",
            "Gradient Descent(393/999): loss=9.122276015972918, w0=-2.9377341314908687, w1=1.0967874567122615\n",
            "Gradient Descent(394/999): loss=9.121064456515574, w0=-2.941188073615738, w1=1.0971344426629879\n",
            "Gradient Descent(395/999): loss=9.119861617119154, w0=-2.9446295636173243, w1=1.0974801776628647\n",
            "Gradient Descent(396/999): loss=9.118667435022022, w0=-2.948058646387919, w1=1.0978246662218092\n",
            "Gradient Descent(397/999): loss=9.117481847914252, w0=-2.951475366657967, w1=1.09816791283348\n",
            "Gradient Descent(398/999): loss=9.11630479393439, w0=-2.9548797689966526, w1=1.0985099219753351\n",
            "Gradient Descent(399/999): loss=9.115136211666217, w0=-2.9582718978124785, w1=1.0988506981086907\n",
            "Gradient Descent(400/999): loss=9.113976040135562, w0=-2.9616517973538468, w1=1.0991902456787779\n",
            "Gradient Descent(401/999): loss=9.112824218807098, w0=-2.965019511709636, w1=1.0995285691148031\n",
            "Gradient Descent(402/999): loss=9.111680687581195, w0=-2.9683750848097747, w1=1.0998656728300045\n",
            "Gradient Descent(403/999): loss=9.110545386790793, w0=-2.971718560425817, w1=1.100201561221709\n",
            "Gradient Descent(404/999): loss=9.109418257198266, w0=-2.9750499821715106, w1=1.1005362386713908\n",
            "Gradient Descent(405/999): loss=9.10829923999235, w0=-2.978369393503369, w1=1.1008697095447282\n",
            "Gradient Descent(406/999): loss=9.107188276785074, w0=-2.9816768377212353, w1=1.10120197819166\n",
            "Gradient Descent(407/999): loss=9.106085309608693, w0=-2.9849723579688487, w1=1.1015330489464428\n",
            "Gradient Descent(408/999): loss=9.104990280912691, w0=-2.9882559972344076, w1=1.101862926127707\n",
            "Gradient Descent(409/999): loss=9.103903133560767, w0=-2.991527798351129, w1=1.1021916140385148\n",
            "Gradient Descent(410/999): loss=9.102823810827836, w0=-2.994787803997808, w1=1.102519116966413\n",
            "Gradient Descent(411/999): loss=9.101752256397106, w0=-2.998036056699375, w1=1.1028454391834932\n",
            "Gradient Descent(412/999): loss=9.100688414357101, w0=-3.001272598827449, w1=1.1031705849464428\n",
            "Gradient Descent(413/999): loss=9.099632229198772, w0=-3.004497472600892, w1=1.1034945584966058\n",
            "Gradient Descent(414/999): loss=9.098583645812587, w0=-3.0077107200863584, w1=1.1038173640600333\n",
            "Gradient Descent(415/999): loss=9.097542609485659, w0=-3.0109123831988445, w1=1.1041390058475409\n",
            "Gradient Descent(416/999): loss=9.096509065898887, w0=-3.014102503702235, w1=1.1044594880547647\n",
            "Gradient Descent(417/999): loss=9.095482961124132, w0=-3.0172811232098478, w1=1.104778814862213\n",
            "Gradient Descent(418/999): loss=9.094464241621393, w0=-3.020448283184977, w1=1.1050969904353243\n",
            "Gradient Descent(419/999): loss=9.093452854236018, w0=-3.0236040249414327, w1=1.1054140189245183\n",
            "Gradient Descent(420/999): loss=9.092448746195926, w0=-3.026748389644082, w1=1.1057299044652527\n",
            "Gradient Descent(421/999): loss=9.091451865108864, w0=-3.0298814183093836, w1=1.1060446511780753\n",
            "Gradient Descent(422/999): loss=9.09046215895966, w0=-3.0330031518059255, w1=1.1063582631686797\n",
            "Gradient Descent(423/999): loss=9.089479576107518, w0=-3.0361136308549552, w1=1.1066707445279562\n",
            "Gradient Descent(424/999): loss=9.08850406528332, w0=-3.0392128960309126, w1=1.106982099332048\n",
            "Gradient Descent(425/999): loss=9.087535575586953, w0=-3.0423009877619593, w1=1.1072923316424022\n",
            "Gradient Descent(426/999): loss=9.086574056484652, w0=-3.0453779463305057, w1=1.1076014455058236\n",
            "Gradient Descent(427/999): loss=9.085619457806358, w0=-3.048443811873736, w1=1.1079094449545284\n",
            "Gradient Descent(428/999): loss=9.084671729743109, w0=-3.051498624384133, w1=1.1082163340061943\n",
            "Gradient Descent(429/999): loss=9.08373082284444, w0=-3.0545424237099974, w1=1.1085221166640162\n",
            "Gradient Descent(430/999): loss=9.082796688015797, w0=-3.0575752495559705, w1=1.1088267969167558\n",
            "Gradient Descent(431/999): loss=9.081869276515977, w0=-3.06059714148355, w1=1.1091303787387945\n",
            "Gradient Descent(432/999): loss=9.08094853995459, w0=-3.063608138911608, w1=1.109432866090185\n",
            "Gradient Descent(433/999): loss=9.08003443028953, w0=-3.0666082811169018, w1=1.1097342629167053\n",
            "Gradient Descent(434/999): loss=9.079126899824464, w0=-3.0695976072345905, w1=1.1100345731499046\n",
            "Gradient Descent(435/999): loss=9.07822590120635, w0=-3.0725761562587426, w1=1.1103338007071615\n",
            "Gradient Descent(436/999): loss=9.077331387422964, w0=-3.075543967042846, w1=1.1106319494917294\n",
            "Gradient Descent(437/999): loss=9.076443311800457, w0=-3.0785010783003135, w1=1.110929023392791\n",
            "Gradient Descent(438/999): loss=9.075561628000889, w0=-3.0814475286049894, w1=1.1112250262855075\n",
            "Gradient Descent(439/999): loss=9.074686290019851, w0=-3.0843833563916516, w1=1.1115199620310687\n",
            "Gradient Descent(440/999): loss=9.073817252184035, w0=-3.087308599956513, w1=1.111813834476745\n",
            "Gradient Descent(441/999): loss=9.072954469148868, w0=-3.090223297457722, w1=1.1121066474559362\n",
            "Gradient Descent(442/999): loss=9.072097895896135, w0=-3.0931274869158587, w1=1.112398404788222\n",
            "Gradient Descent(443/999): loss=9.071247487731634, w0=-3.0960212062144326, w1=1.1126891102794116\n",
            "Gradient Descent(444/999): loss=9.070403200282849, w0=-3.098904493100375, w1=1.112978767721594\n",
            "Gradient Descent(445/999): loss=9.069564989496625, w0=-3.101777385184533, w1=1.1132673808931868\n",
            "Gradient Descent(446/999): loss=9.068732811636876, w0=-3.104639919942159, w1=1.1135549535589853\n",
            "Gradient Descent(447/999): loss=9.067906623282303, w0=-3.1074921347134, w1=1.1138414894702122\n",
            "Gradient Descent(448/999): loss=9.067086381324124, w0=-3.110334066703785, w1=1.114126992364567\n",
            "Gradient Descent(449/999): loss=9.066272042963835, w0=-3.113165752984709, w1=1.114411465966273\n",
            "Gradient Descent(450/999): loss=9.065463565710958, w0=-3.115987230493919, w1=1.1146949139861273\n",
            "Gradient Descent(451/999): loss=9.064660907380844, w0=-3.118798536035993, w1=1.1149773401215497\n",
            "Gradient Descent(452/999): loss=9.063864026092464, w0=-3.121599706282822, w1=1.1152587480566287\n",
            "Gradient Descent(453/999): loss=9.063072880266214, w0=-3.124390777774087, w1=1.1155391414621723\n",
            "Gradient Descent(454/999): loss=9.062287428621758, w0=-3.127171786917738, w1=1.1158185239957532\n",
            "Gradient Descent(455/999): loss=9.061507630175882, w0=-3.1299427699904663, w1=1.1160968993017595\n",
            "Gradient Descent(456/999): loss=9.060733444240325, w0=-3.132703763138179, w1=1.1163742710114384\n",
            "Gradient Descent(457/999): loss=9.059964830419688, w0=-3.1354548023764703, w1=1.1166506427429483\n",
            "Gradient Descent(458/999): loss=9.05920174860931, w0=-3.1381959235910912, w1=1.1169260181014011\n",
            "Gradient Descent(459/999): loss=9.058444158993177, w0=-3.140927162538418, w1=1.1172004006789131\n",
            "Gradient Descent(460/999): loss=9.057692022041852, w0=-3.1436485548459174, w1=1.11747379405465\n",
            "Gradient Descent(461/999): loss=9.056945298510394, w0=-3.146360136012614, w1=1.1177462017948734\n",
            "Gradient Descent(462/999): loss=9.056203949436341, w0=-3.14906194140955, w1=1.1180176274529883\n",
            "Gradient Descent(463/999): loss=9.055467936137642, w0=-3.151754006280249, w1=1.118288074569589\n",
            "Gradient Descent(464/999): loss=9.054737220210667, w0=-3.154436365741175, w1=1.1185575466725053\n",
            "Gradient Descent(465/999): loss=9.054011763528186, w0=-3.15710905478219, w1=1.1188260472768479\n",
            "Gradient Descent(466/999): loss=9.053291528237386, w0=-3.1597721082670107, w1=1.119093579885056\n",
            "Gradient Descent(467/999): loss=9.052576476757897, w0=-3.1624255609336642, w1=1.1193601479869408\n",
            "Gradient Descent(468/999): loss=9.05186657177983, w0=-3.16506944739494, w1=1.1196257550597326\n",
            "Gradient Descent(469/999): loss=9.051161776261825, w0=-3.1677038021388415, w1=1.119890404568125\n",
            "Gradient Descent(470/999): loss=9.05046205342913, w0=-3.1703286595290368, w1=1.120154099964322\n",
            "Gradient Descent(471/999): loss=9.04976736677167, w0=-3.1729440538053058, w1=1.1204168446880802\n",
            "Gradient Descent(472/999): loss=9.049077680042148, w0=-3.1755500190839876, w1=1.120678642166756\n",
            "Gradient Descent(473/999): loss=9.048392957254155, w0=-3.178146589358426, w1=1.12093949581535\n",
            "Gradient Descent(474/999): loss=9.047713162680285, w0=-3.1807337984994115, w1=1.1211994090365498\n",
            "Gradient Descent(475/999): loss=9.047038260850284, w0=-3.183311680255624, w1=1.121458385220777\n",
            "Gradient Descent(476/999): loss=9.04636821654918, w0=-3.1858802682540737, w1=1.1217164277462288\n",
            "Gradient Descent(477/999): loss=9.045702994815468, w0=-3.188439596000538, w1=1.1219735399789248\n",
            "Gradient Descent(478/999): loss=9.045042560939265, w0=-3.19098969688, w1=1.1222297252727482\n",
            "Gradient Descent(479/999): loss=9.04438688046052, w0=-3.1935306041570835, w1=1.122484986969491\n",
            "Gradient Descent(480/999): loss=9.043735919167194, w0=-3.196062350976487, w1=1.1227393283988985\n",
            "Gradient Descent(481/999): loss=9.043089643093486, w0=-3.198584970363416, w1=1.12299275287871\n",
            "Gradient Descent(482/999): loss=9.042448018518067, w0=-3.201098495224014, w1=1.123245263714705\n",
            "Gradient Descent(483/999): loss=9.041811011962308, w0=-3.203602958345791, w1=1.1234968642007443\n",
            "Gradient Descent(484/999): loss=9.041178590188533, w0=-3.2060983923980517, w1=1.1237475576188143\n",
            "Gradient Descent(485/999): loss=9.040550720198304, w0=-3.208584829932323, w1=1.1239973472390683\n",
            "Gradient Descent(486/999): loss=9.039927369230677, w0=-3.211062303382776, w1=1.1242462363198713\n",
            "Gradient Descent(487/999): loss=9.039308504760498, w0=-3.2135308450666504, w1=1.1244942281078398\n",
            "Gradient Descent(488/999): loss=9.03869409449672, w0=-3.2159904871846767, w1=1.1247413258378873\n",
            "Gradient Descent(489/999): loss=9.038084106380698, w0=-3.218441261821495, w1=1.1249875327332632\n",
            "Gradient Descent(490/999): loss=9.03747850858453, w0=-3.220883200946075, w1=1.1252328520055979\n",
            "Gradient Descent(491/999): loss=9.036877269509386, w0=-3.223316336412131, w1=1.125477286854942\n",
            "Gradient Descent(492/999): loss=9.036280357783872, w0=-3.2257406999585396, w1=1.1257208404698098\n",
            "Gradient Descent(493/999): loss=9.03568774226238, w0=-3.228156323209752, w1=1.1259635160272214\n",
            "Gradient Descent(494/999): loss=9.035099392023474, w0=-3.2305632376762077, w1=1.1262053166927408\n",
            "Gradient Descent(495/999): loss=9.034515276368271, w0=-3.2329614747547444, w1=1.1264462456205224\n",
            "Gradient Descent(496/999): loss=9.033935364818836, w0=-3.2353510657290085, w1=1.1266863059533467\n",
            "Gradient Descent(497/999): loss=9.033359627116596, w0=-3.237732041769863, w1=1.1269255008226655\n",
            "Gradient Descent(498/999): loss=9.032788033220765, w0=-3.2401044339357936, w1=1.1271638333486405\n",
            "Gradient Descent(499/999): loss=9.032220553306768, w0=-3.2424682731733148, w1=1.1274013066401845\n",
            "Gradient Descent(500/999): loss=9.031657157764688, w0=-3.244823590317372, w1=1.1276379237950027\n",
            "Gradient Descent(501/999): loss=9.031097817197729, w0=-3.247170416091746, w1=1.1278736878996316\n",
            "Gradient Descent(502/999): loss=9.030542502420667, w0=-3.2495087811094514, w1=1.1281086020294813\n",
            "Gradient Descent(503/999): loss=9.029991184458341, w0=-3.251838715873138, w1=1.1283426692488727\n",
            "Gradient Descent(504/999): loss=9.02944383454413, w0=-3.2541602507754863, w1=1.1285758926110816\n",
            "Gradient Descent(505/999): loss=9.028900424118463, w0=-3.256473416099607, w1=1.1288082751583737\n",
            "Gradient Descent(506/999): loss=9.028360924827318, w0=-3.258778242019433, w1=1.1290398199220488\n",
            "Gradient Descent(507/999): loss=9.027825308520756, w0=-3.261074758600115, w1=1.1292705299224768\n",
            "Gradient Descent(508/999): loss=9.027293547251432, w0=-3.2633629957984134, w1=1.1295004081691393\n",
            "Gradient Descent(509/999): loss=9.02676561327316, w0=-3.265642983463088, w1=1.1297294576606682\n",
            "Gradient Descent(510/999): loss=9.026241479039447, w0=-3.267914751335289, w1=1.1299576813848846\n",
            "Gradient Descent(511/999): loss=9.025721117202067, w0=-3.270178329048943, w1=1.1301850823188377\n",
            "Gradient Descent(512/999): loss=9.025204500609627, w0=-3.2724337461311412, w1=1.1304116634288444\n",
            "Gradient Descent(513/999): loss=9.024691602306154, w0=-3.2746810320025244, w1=1.1306374276705267\n",
            "Gradient Descent(514/999): loss=9.024182395529689, w0=-3.276920215977665, w1=1.1308623779888518\n",
            "Gradient Descent(515/999): loss=9.023676853710883, w0=-3.2791513272654527, w1=1.131086517318169\n",
            "Gradient Descent(516/999): loss=9.023174950471624, w0=-3.281374394969472, w1=1.1313098485822497\n",
            "Gradient Descent(517/999): loss=9.022676659623656, w0=-3.2835894480883834, w1=1.1315323746943236\n",
            "Gradient Descent(518/999): loss=9.022181955167197, w0=-3.285796515516303, w1=1.1317540985571177\n",
            "Gradient Descent(519/999): loss=9.02169081128961, w0=-3.2879956260431764, w1=1.1319750230628949\n",
            "Gradient Descent(520/999): loss=9.02120320236403, w0=-3.2901868083551573, w1=1.1321951510934902\n",
            "Gradient Descent(521/999): loss=9.020719102948044, w0=-3.2923700910349796, w1=1.1324144855203493\n",
            "Gradient Descent(522/999): loss=9.020238487782358, w0=-3.294545502562331, w1=1.1326330292045657\n",
            "Gradient Descent(523/999): loss=9.01976133178948, w0=-3.296713071314225, w1=1.1328507849969183\n",
            "Gradient Descent(524/999): loss=9.019287610072409, w0=-3.29887282556537, w1=1.133067755737908\n",
            "Gradient Descent(525/999): loss=9.01881729791333, w0=-3.3010247934885384, w1=1.1332839442577958\n",
            "Gradient Descent(526/999): loss=9.018350370772346, w0=-3.303169003154935, w1=1.1334993533766384\n",
            "Gradient Descent(527/999): loss=9.017886804286174, w0=-3.3053054825345622, w1=1.133713985904326\n",
            "Gradient Descent(528/999): loss=9.017426574266882, w0=-3.3074342594965853, w1=1.1339278446406187\n",
            "Gradient Descent(529/999): loss=9.016969656700631, w0=-3.309555361809696, w1=1.134140932375182\n",
            "Gradient Descent(530/999): loss=9.01651602774642, w0=-3.3116688171424746, w1=1.1343532518876265\n",
            "Gradient Descent(531/999): loss=9.016065663734837, w0=-3.31377465306375, w1=1.1345648059475384\n",
            "Gradient Descent(532/999): loss=9.015618541166834, w0=-3.315872897042962, w1=1.1347755973145217\n",
            "Gradient Descent(533/999): loss=9.015174636712484, w0=-3.3179635764505155, w1=1.1349856287382307\n",
            "Gradient Descent(534/999): loss=9.014733927209786, w0=-3.3200467185581415, w1=1.1351949029584059\n",
            "Gradient Descent(535/999): loss=9.01429638966344, w0=-3.3221223505392508, w1=1.135403422704912\n",
            "Gradient Descent(536/999): loss=9.013862001243652, w0=-3.324190499469289, w1=1.13561119069777\n",
            "Gradient Descent(537/999): loss=9.013430739284942, w0=-3.3262511923260885, w1=1.1358182096471972\n",
            "Gradient Descent(538/999): loss=9.013002581284962, w0=-3.3283044559902226, w1=1.1360244822536374\n",
            "Gradient Descent(539/999): loss=9.012577504903328, w0=-3.330350317245355, w1=1.1362300112078014\n",
            "Gradient Descent(540/999): loss=9.012155487960438, w0=-3.3323888027785884, w1=1.1364347991906971\n",
            "Gradient Descent(541/999): loss=9.011736508436332, w0=-3.3344199391808136, w1=1.1366388488736685\n",
            "Gradient Descent(542/999): loss=9.011320544469537, w0=-3.3364437529470568, w1=1.1368421629184282\n",
            "Gradient Descent(543/999): loss=9.010907574355926, w0=-3.3384602704768236, w1=1.137044743977093\n",
            "Gradient Descent(544/999): loss=9.010497576547575, w0=-3.340469518074445, w1=1.137246594692218\n",
            "Gradient Descent(545/999): loss=9.010090529651661, w0=-3.3424715219494194, w1=1.1374477176968318\n",
            "Gradient Descent(546/999): loss=9.00968641242933, w0=-3.3444663082167554, w1=1.1376481156144702\n",
            "Gradient Descent(547/999): loss=9.009285203794583, w0=-3.3464539028973115, w1=1.1378477910592109\n",
            "Gradient Descent(548/999): loss=9.008886882813202, w0=-3.348434331918136, w1=1.1380467466357067\n",
            "Gradient Descent(549/999): loss=9.008491428701626, w0=-3.3504076211128067, w1=1.138244984939221\n",
            "Gradient Descent(550/999): loss=9.00809882082589, w0=-3.3523737962217637, w1=1.1384425085556604\n",
            "Gradient Descent(551/999): loss=9.007709038700533, w0=-3.35433288289265, w1=1.1386393200616085\n",
            "Gradient Descent(552/999): loss=9.007322061987539, w0=-3.3562849066806435, w1=1.13883542202436\n",
            "Gradient Descent(553/999): loss=9.00693787049528, w0=-3.35822989304879, w1=1.1390308170019547\n",
            "Gradient Descent(554/999): loss=9.006556444177438, w0=-3.3601678673683377, w1=1.1392255075432085\n",
            "Gradient Descent(555/999): loss=9.006177763131989, w0=-3.3620988549190645, w1=1.1394194961877508\n",
            "Gradient Descent(556/999): loss=9.005801807600152, w0=-3.3640228808896113, w1=1.1396127854660525\n",
            "Gradient Descent(557/999): loss=9.005428557965349, w0=-3.3659399703778092, w1=1.139805377899464\n",
            "Gradient Descent(558/999): loss=9.005057994752196, w0=-3.367850148391006, w1=1.1399972760002437\n",
            "Gradient Descent(559/999): loss=9.004690098625481, w0=-3.3697534398463937, w1=1.1401884822715942\n",
            "Gradient Descent(560/999): loss=9.004324850389152, w0=-3.3716498695713333, w1=1.1403789992076936\n",
            "Gradient Descent(561/999): loss=9.003962230985323, w0=-3.3735394623036776, w1=1.1405688292937266\n",
            "Gradient Descent(562/999): loss=9.003602221493269, w0=-3.3754222426920952, w1=1.1407579750059207\n",
            "Gradient Descent(563/999): loss=9.00324480312845, w0=-3.377298235296392, w1=1.140946438811573\n",
            "Gradient Descent(564/999): loss=9.002889957241523, w0=-3.37916746458783, w1=1.1411342231690893\n",
            "Gradient Descent(565/999): loss=9.002537665317371, w0=-3.3810299549494482, w1=1.1413213305280085\n",
            "Gradient Descent(566/999): loss=9.00218790897414, w0=-3.38288573067638, w1=1.1415077633290414\n",
            "Gradient Descent(567/999): loss=9.001840669962274, w0=-3.384734815976171, w1=1.141693524004098\n",
            "Gradient Descent(568/999): loss=9.001495930163568, w0=-3.3865772349690926, w1=1.1418786149763211\n",
            "Gradient Descent(569/999): loss=9.00115367159022, w0=-3.3884130116884585, w1=1.1420630386601185\n",
            "Gradient Descent(570/999): loss=9.000813876383898, w0=-3.3902421700809384, w1=1.142246797461192\n",
            "Gradient Descent(571/999): loss=9.000476526814793, w0=-3.3920647340068686, w1=1.142429893776572\n",
            "Gradient Descent(572/999): loss=9.000141605280712, w0=-3.393880727240565, w1=1.1426123299946456\n",
            "Gradient Descent(573/999): loss=8.999809094306153, w0=-3.3956901734706317, w1=1.1427941084951907\n",
            "Gradient Descent(574/999): loss=8.999478976541386, w0=-3.3974930963002725, w1=1.1429752316494048\n",
            "Gradient Descent(575/999): loss=8.999151234761557, w0=-3.3992895192475956, w1=1.143155701819937\n",
            "Gradient Descent(576/999): loss=8.998825851865785, w0=-3.4010794657459225, w1=1.1433355213609189\n",
            "Gradient Descent(577/999): loss=8.998502810876273, w0=-3.402862959144093, w1=1.143514692617994\n",
            "Gradient Descent(578/999): loss=8.998182094937416, w0=-3.4046400227067695, w1=1.143693217928351\n",
            "Gradient Descent(579/999): loss=8.99786368731493, w0=-3.4064106796147415, w1=1.1438710996207506\n",
            "Gradient Descent(580/999): loss=8.99754757139497, w0=-3.408174952965227, w1=1.1440483400155599\n",
            "Gradient Descent(581/999): loss=8.997233730683268, w0=-3.409932865772174, w1=1.1442249414247787\n",
            "Gradient Descent(582/999): loss=8.99692214880427, w0=-3.4116844409665608, w1=1.1444009061520732\n",
            "Gradient Descent(583/999): loss=8.996612809500292, w0=-3.4134297013966957, w1=1.1445762364928032\n",
            "Gradient Descent(584/999): loss=8.996305696630648, w0=-3.4151686698285135, w1=1.1447509347340543\n",
            "Gradient Descent(585/999): loss=8.996000794170838, w0=-3.416901368945874, w1=1.144925003154666\n",
            "Gradient Descent(586/999): loss=8.995698086211684, w0=-3.4186278213508574, w1=1.1450984440252625\n",
            "Gradient Descent(587/999): loss=8.995397556958523, w0=-3.4203480495640592, w1=1.1452712596082817\n",
            "Gradient Descent(588/999): loss=8.995099190730363, w0=-3.422062076024883, w1=1.1454434521580055\n",
            "Gradient Descent(589/999): loss=8.994802971959082, w0=-3.4237699230918355, w1=1.1456150239205878\n",
            "Gradient Descent(590/999): loss=8.994508885188601, w0=-3.425471613042815, w1=1.145785977134086\n",
            "Gradient Descent(591/999): loss=8.994216915074087, w0=-3.4271671680754054, w1=1.1459563140284872\n",
            "Gradient Descent(592/999): loss=8.993927046381156, w0=-3.4288566103071627, w1=1.1461260368257404\n",
            "Gradient Descent(593/999): loss=8.993639263985061, w0=-3.430539961775905, w1=1.1462951477397836\n",
            "Gradient Descent(594/999): loss=8.99335355286992, w0=-3.4322172444400008, w1=1.1464636489765725\n",
            "Gradient Descent(595/999): loss=8.99306989812792, w0=-3.433888480178654, w1=1.1466315427341107\n",
            "Gradient Descent(596/999): loss=8.99278828495856, w0=-3.435553690792189, w1=1.1467988312024777\n",
            "Gradient Descent(597/999): loss=8.992508698667846, w0=-3.4372128980023366, w1=1.1469655165638566\n",
            "Gradient Descent(598/999): loss=8.992231124667553, w0=-3.438866123452517, w1=1.1471316009925634\n",
            "Gradient Descent(599/999): loss=8.991955548474449, w0=-3.4405133887081214, w1=1.1472970866550762\n",
            "Gradient Descent(600/999): loss=8.991681955709547, w0=-3.442154715256793, w1=1.1474619757100615\n",
            "Gradient Descent(601/999): loss=8.991410332097347, w0=-3.443790124508708, w1=1.1476262703084035\n",
            "Gradient Descent(602/999): loss=8.991140663465098, w0=-3.4454196377968564, w1=1.147789972593233\n",
            "Gradient Descent(603/999): loss=8.990872935742054, w0=-3.447043276377317, w1=1.147953084699953\n",
            "Gradient Descent(604/999): loss=8.990607134958745, w0=-3.448661061429536, w1=1.1481156087562696\n",
            "Gradient Descent(605/999): loss=8.990343247246237, w0=-3.450273014056606, w1=1.148277546882216\n",
            "Gradient Descent(606/999): loss=8.990081258835426, w0=-3.451879155285536, w1=1.1484389011901845\n",
            "Gradient Descent(607/999): loss=8.989821156056305, w0=-3.4534795060675307, w1=1.1485996737849502\n",
            "Gradient Descent(608/999): loss=8.989562925337252, w0=-3.455074087278261, w1=1.1487598667637013\n",
            "Gradient Descent(609/999): loss=8.989306553204328, w0=-3.456662919718137, w1=1.1489194822160635\n",
            "Gradient Descent(610/999): loss=8.989052026280575, w0=-3.458246024112579, w1=1.1490785222241315\n",
            "Gradient Descent(611/999): loss=8.988799331285307, w0=-3.459823421112289, w1=1.1492369888624914\n",
            "Gradient Descent(612/999): loss=8.988548455033433, w0=-3.4613951312935187, w1=1.1493948841982509\n",
            "Gradient Descent(613/999): loss=8.988299384434749, w0=-3.4629611751583385, w1=1.1495522102910656\n",
            "Gradient Descent(614/999): loss=8.988052106493274, w0=-3.4645215731349044, w1=1.1497089691931652\n",
            "Gradient Descent(615/999): loss=8.987806608306563, w0=-3.466076345577726, w1=1.1498651629493812\n",
            "Gradient Descent(616/999): loss=8.987562877065038, w0=-3.467625512767931, w1=1.1500207935971725\n",
            "Gradient Descent(617/999): loss=8.987320900051307, w0=-3.469169094913529, w1=1.1501758631666532\n",
            "Gradient Descent(618/999): loss=8.987080664639516, w0=-3.4707071121496758, w1=1.1503303736806179\n",
            "Gradient Descent(619/999): loss=8.986842158294685, w0=-3.4722395845389364, w1=1.150484327154569\n",
            "Gradient Descent(620/999): loss=8.986605368572054, w0=-3.4737665320715467, w1=1.1506377255967424\n",
            "Gradient Descent(621/999): loss=8.986370283116429, w0=-3.4752879746656737, w1=1.1507905710081343\n",
            "Gradient Descent(622/999): loss=8.98613688966154, w0=-3.476803932167676, w1=1.150942865382526\n",
            "Gradient Descent(623/999): loss=8.98590517602941, w0=-3.4783144243523614, w1=1.1510946107065125\n",
            "Gradient Descent(624/999): loss=8.985675130129703, w0=-3.479819470923246, w1=1.1512458089595246\n",
            "Gradient Descent(625/999): loss=8.985446739959105, w0=-3.481319091512812, w1=1.151396462113859\n",
            "Gradient Descent(626/999): loss=8.985219993600696, w0=-3.4828133056827615, w1=1.1515465721347002\n",
            "Gradient Descent(627/999): loss=8.984994879223327, w0=-3.484302132924273, w1=1.151696140980149\n",
            "Gradient Descent(628/999): loss=8.984771385080995, w0=-3.485785592658256, w1=1.151845170601246\n",
            "Gradient Descent(629/999): loss=8.98454949951225, w0=-3.487263704235604, w1=1.1519936629419987\n",
            "Gradient Descent(630/999): loss=8.984329210939562, w0=-3.4887364869374466, w1=1.1521416199394052\n",
            "Gradient Descent(631/999): loss=8.984110507868737, w0=-3.490203959975401, w1=1.1522890435234814\n",
            "Gradient Descent(632/999): loss=8.983893378888306, w0=-3.491666142491823, w1=1.1524359356172844\n",
            "Gradient Descent(633/999): loss=8.983677812668931, w0=-3.493123053560057, w1=1.1525822981369385\n",
            "Gradient Descent(634/999): loss=8.983463797962823, w0=-3.4945747121846837, w1=1.1527281329916599\n",
            "Gradient Descent(635/999): loss=8.983251323603135, w0=-3.4960211373017693, w1=1.1528734420837816\n",
            "Gradient Descent(636/999): loss=8.983040378503404, w0=-3.497462347779111, w1=1.1530182273087792\n",
            "Gradient Descent(637/999): loss=8.982830951656956, w0=-3.4988983624164844, w1=1.1531624905552933\n",
            "Gradient Descent(638/999): loss=8.982623032136331, w0=-3.5003291999458885, w1=1.1533062337051572\n",
            "Gradient Descent(639/999): loss=8.982416609092732, w0=-3.5017548790317896, w1=1.1534494586334179\n",
            "Gradient Descent(640/999): loss=8.982211671755433, w0=-3.5031754182713652, w1=1.1535921672083649\n",
            "Gradient Descent(641/999): loss=8.982008209431228, w0=-3.5045908361947467, w1=1.1537343612915496\n",
            "Gradient Descent(642/999): loss=8.981806211503882, w0=-3.50600115126526, w1=1.1538760427378143\n",
            "Gradient Descent(643/999): loss=8.981605667433568, w0=-3.507406381879667, w1=1.1540172133953128\n",
            "Gradient Descent(644/999): loss=8.981406566756313, w0=-3.5088065463684073, w1=1.154157875105537\n",
            "Gradient Descent(645/999): loss=8.981208899083459, w0=-3.5102016629958346, w1=1.1542980297033387\n",
            "Gradient Descent(646/999): loss=8.981012654101125, w0=-3.511591749960456, w1=1.1544376790169562\n",
            "Gradient Descent(647/999): loss=8.980817821569653, w0=-3.5129768253951705, w1=1.1545768248680348\n",
            "Gradient Descent(648/999): loss=8.980624391323095, w0=-3.514356907367503, w1=1.1547154690716546\n",
            "Gradient Descent(649/999): loss=8.980432353268657, w0=-3.515732013879843, w1=1.1548536134363496\n",
            "Gradient Descent(650/999): loss=8.980241697386207, w0=-3.517102162869677, w1=1.1549912597641359\n",
            "Gradient Descent(651/999): loss=8.980052413727705, w0=-3.518467372209823, w1=1.1551284098505314\n",
            "Gradient Descent(652/999): loss=8.979864492416741, w0=-3.519827659708666, w1=1.155265065484582\n",
            "Gradient Descent(653/999): loss=8.979677923647962, w0=-3.521183043110387, w1=1.1554012284488824\n",
            "Gradient Descent(654/999): loss=8.979492697686608, w0=-3.5225335400951954, w1=1.1555369005196021\n",
            "Gradient Descent(655/999): loss=8.979308804867971, w0=-3.5238791682795605, w1=1.1556720834665064\n",
            "Gradient Descent(656/999): loss=8.97912623559691, w0=-3.5252199452164414, w1=1.1558067790529798\n",
            "Gradient Descent(657/999): loss=8.978944980347341, w0=-3.526555888395515, w1=1.1559409890360512\n",
            "Gradient Descent(658/999): loss=8.97876502966175, w0=-3.527887015243404, w1=1.1560747151664128\n",
            "Gradient Descent(659/999): loss=8.978586374150677, w0=-3.529213343123906, w1=1.156207959188447\n",
            "Gradient Descent(660/999): loss=8.978409004492258, w0=-3.530534889338218, w1=1.1563407228402467\n",
            "Gradient Descent(661/999): loss=8.978232911431714, w0=-3.5318516711251626, w1=1.1564730078536383\n",
            "Gradient Descent(662/999): loss=8.978058085780878, w0=-3.533163705661414, w1=1.156604815954205\n",
            "Gradient Descent(663/999): loss=8.977884518417714, w0=-3.5344710100617203, w1=1.1567361488613095\n",
            "Gradient Descent(664/999): loss=8.977712200285838, w0=-3.535773601379128, w1=1.1568670082881145\n",
            "Gradient Descent(665/999): loss=8.977541122394047, w0=-3.537071496605205, w1=1.156997395941608\n",
            "Gradient Descent(666/999): loss=8.977371275815862, w0=-3.5383647126702598, w1=1.1571273135226228\n",
            "Gradient Descent(667/999): loss=8.97720265168904, w0=-3.5396532664435645, w1=1.1572567627258599\n",
            "Gradient Descent(668/999): loss=8.977035241215127, w0=-3.5409371747335747, w1=1.157385745239912\n",
            "Gradient Descent(669/999): loss=8.976869035658995, w0=-3.5422164542881482, w1=1.1575142627472816\n",
            "Gradient Descent(670/999): loss=8.976704026348386, w0=-3.5434911217947627, w1=1.1576423169244083\n",
            "Gradient Descent(671/999): loss=8.976540204673457, w0=-3.5447611938807353, w1=1.1577699094416853\n",
            "Gradient Descent(672/999): loss=8.97637756208634, w0=-3.546026687113438, w1=1.157897041963486\n",
            "Gradient Descent(673/999): loss=8.976216090100682, w0=-3.5472876180005146, w1=1.1580237161481812\n",
            "Gradient Descent(674/999): loss=8.976055780291212, w0=-3.548544002990095, w1=1.1581499336481647\n",
            "Gradient Descent(675/999): loss=8.975896624293302, w0=-3.549795858471011, w1=1.1582756961098717\n",
            "Gradient Descent(676/999): loss=8.975738613802525, w0=-3.5510432007730097, w1=1.1584010051738032\n",
            "Gradient Descent(677/999): loss=8.975581740574222, w0=-3.552286046166966, w1=1.1585258624745443\n",
            "Gradient Descent(678/999): loss=8.975425996423075, w0=-3.5535244108650943, w1=1.1586502696407885\n",
            "Gradient Descent(679/999): loss=8.975271373222684, w0=-3.5547583110211627, w1=1.1587742282953564\n",
            "Gradient Descent(680/999): loss=8.975117862905131, w0=-3.5559877627307004, w1=1.1588977400552192\n",
            "Gradient Descent(681/999): loss=8.974965457460572, w0=-3.5572127820312103, w1=1.1590208065315173\n",
            "Gradient Descent(682/999): loss=8.974814148936806, w0=-3.5584333849023757, w1=1.1591434293295837\n",
            "Gradient Descent(683/999): loss=8.974663929438874, w0=-3.559649587266271, w1=1.1592656100489633\n",
            "Gradient Descent(684/999): loss=8.974514791128632, w0=-3.5608614049875684, w1=1.1593873502834344\n",
            "Gradient Descent(685/999): loss=8.97436672622436, w0=-3.5620688538737446, w1=1.1595086516210298\n",
            "Gradient Descent(686/999): loss=8.974219727000337, w0=-3.5632719496752876, w1=1.1596295156440564\n",
            "Gradient Descent(687/999): loss=8.974073785786457, w0=-3.5644707080859015, w1=1.1597499439291177\n",
            "Gradient Descent(688/999): loss=8.973928894967807, w0=-3.565665144742712, w1=1.1598699380471318\n",
            "Gradient Descent(689/999): loss=8.973785046984288, w0=-3.56685527522647, w1=1.1599894995633546\n",
            "Gradient Descent(690/999): loss=8.973642234330214, w0=-3.568041115061754, w1=1.1601086300373982\n",
            "Gradient Descent(691/999): loss=8.97350044955392, w0=-3.5692226797171744, w1=1.1602273310232527\n",
            "Gradient Descent(692/999): loss=8.973359685257375, w0=-3.570399984605574, w1=1.1603456040693048\n",
            "Gradient Descent(693/999): loss=8.97321993409579, w0=-3.571573045084229, w1=1.1604634507183598\n",
            "Gradient Descent(694/999): loss=8.97308118877724, w0=-3.57274187645505, w1=1.1605808725076605\n",
            "Gradient Descent(695/999): loss=8.972943442062286, w0=-3.5739064939647815, w1=1.1606978709689078\n",
            "Gradient Descent(696/999): loss=8.972806686763592, w0=-3.5750669128052, w1=1.1608144476282802\n",
            "Gradient Descent(697/999): loss=8.972670915745557, w0=-3.576223148113313, w1=1.1609306040064549\n",
            "Gradient Descent(698/999): loss=8.972536121923929, w0=-3.577375214971556, w1=1.1610463416186254\n",
            "Gradient Descent(699/999): loss=8.972402298265447, w0=-3.57852312840799, w1=1.161161661974524\n",
            "Gradient Descent(700/999): loss=8.972269437787478, w0=-3.5796669033964967, w1=1.161276566578439\n",
            "Gradient Descent(701/999): loss=8.972137533557634, w0=-3.580806554856974, w1=1.1613910569292365\n",
            "Gradient Descent(702/999): loss=8.972006578693431, w0=-3.5819420976555305, w1=1.1615051345203782\n",
            "Gradient Descent(703/999): loss=8.971876566361923, w0=-3.58307354660468, w1=1.1616188008399415\n",
            "Gradient Descent(704/999): loss=8.971747489779329, w0=-3.5842009164635336, w1=1.1617320573706398\n",
            "Gradient Descent(705/999): loss=8.97161934221071, w0=-3.585324221937994, w1=1.1618449055898397\n",
            "Gradient Descent(706/999): loss=8.971492116969593, w0=-3.586443477680946, w1=1.1619573469695834\n",
            "Gradient Descent(707/999): loss=8.971365807417627, w0=-3.5875586982924474, w1=1.162069382976604\n",
            "Gradient Descent(708/999): loss=8.971240406964245, w0=-3.5886698983199206, w1=1.1621810150723488\n",
            "Gradient Descent(709/999): loss=8.97111590906632, w0=-3.589777092258341, w1=1.1622922447129949\n",
            "Gradient Descent(710/999): loss=8.970992307227805, w0=-3.5908802945504283, w1=1.16240307334947\n",
            "Gradient Descent(711/999): loss=8.970869594999417, w0=-3.591979519586832, w1=1.162513502427471\n",
            "Gradient Descent(712/999): loss=8.970747765978288, w0=-3.593074781706321, w1=1.1626235333874835\n",
            "Gradient Descent(713/999): loss=8.970626813807637, w0=-3.5941660951959706, w1=1.1627331676647976\n",
            "Gradient Descent(714/999): loss=8.97050673217643, w0=-3.5952534742913476, w1=1.1628424066895322\n",
            "Gradient Descent(715/999): loss=8.97038751481906, w0=-3.5963369331766977, w1=1.1629512518866474\n",
            "Gradient Descent(716/999): loss=8.970269155515014, w0=-3.597416485985129, w1=1.1630597046759679\n",
            "Gradient Descent(717/999): loss=8.970151648088553, w0=-3.598492146798798, w1=1.1631677664721982\n",
            "Gradient Descent(718/999): loss=8.970034986408383, w0=-3.599563929649091, w1=1.1632754386849444\n",
            "Gradient Descent(719/999): loss=8.96991916438734, w0=-3.6006318485168096, w1=1.1633827227187286\n",
            "Gradient Descent(720/999): loss=8.96980417598208, w0=-3.6016959173323513, w1=1.1634896199730114\n",
            "Gradient Descent(721/999): loss=8.969690015192743, w0=-3.602756149975892, w1=1.163596131842206\n",
            "Gradient Descent(722/999): loss=8.969576676062658, w0=-3.603812560277567, w1=1.1637022597157\n",
            "Gradient Descent(723/999): loss=8.969464152678025, w0=-3.604865162017651, w1=1.1638080049778714\n",
            "Gradient Descent(724/999): loss=8.969352439167615, w0=-3.605913968926739, w1=1.1639133690081076\n",
            "Gradient Descent(725/999): loss=8.969241529702447, w0=-3.6069589946859235, w1=1.1640183531808224\n",
            "Gradient Descent(726/999): loss=8.969131418495499, w0=-3.6080002529269746, w1=1.1641229588654751\n",
            "Gradient Descent(727/999): loss=8.969022099801393, w0=-3.6090377572325174, w1=1.1642271874265875\n",
            "Gradient Descent(728/999): loss=8.968913567916113, w0=-3.6100715211362084, w1=1.164331040223763\n",
            "Gradient Descent(729/999): loss=8.968805817176694, w0=-3.611101558122914, w1=1.1644345186117016\n",
            "Gradient Descent(730/999): loss=8.968698841960922, w0=-3.612127881628883, w1=1.1645376239402212\n",
            "Gradient Descent(731/999): loss=8.968592636687061, w0=-3.6131505050419257, w1=1.1646403575542716\n",
            "Gradient Descent(732/999): loss=8.968487195813536, w0=-3.6141694417015864, w1=1.1647427207939556\n",
            "Gradient Descent(733/999): loss=8.968382513838664, w0=-3.6151847048993173, w1=1.1648447149945433\n",
            "Gradient Descent(734/999): loss=8.968278585300359, w0=-3.6161963078786528, w1=1.1649463414864913\n",
            "Gradient Descent(735/999): loss=8.968175404775852, w0=-3.617204263835381, w1=1.1650476015954603\n",
            "Gradient Descent(736/999): loss=8.968072966881394, w0=-3.6182085859177184, w1=1.1651484966423302\n",
            "Gradient Descent(737/999): loss=8.96797126627199, w0=-3.619209287226478, w1=1.1652490279432206\n",
            "Gradient Descent(738/999): loss=8.967870297641113, w0=-3.6202063808152425, w1=1.165349196809505\n",
            "Gradient Descent(739/999): loss=8.967770055720438, w0=-3.6211998796905336, w1=1.1654490045478303\n",
            "Gradient Descent(740/999): loss=8.967670535279547, w0=-3.6221897968119827, w1=1.165548452460131\n",
            "Gradient Descent(741/999): loss=8.967571731125672, w0=-3.623176145092499, w1=1.1656475418436496\n",
            "Gradient Descent(742/999): loss=8.967473638103419, w0=-3.624158937398437, w1=1.165746273990951\n",
            "Gradient Descent(743/999): loss=8.967376251094496, w0=-3.625138186549768, w1=1.1658446501899398\n",
            "Gradient Descent(744/999): loss=8.967279565017458, w0=-3.626113905320242, w1=1.1659426717238783\n",
            "Gradient Descent(745/999): loss=8.967183574827427, w0=-3.6270861064375595, w1=1.166040339871402\n",
            "Gradient Descent(746/999): loss=8.96708827551583, w0=-3.628054802583534, w1=1.1661376559065364\n",
            "Gradient Descent(747/999): loss=8.966993662110157, w0=-3.6290200063942586, w1=1.1662346210987142\n",
            "Gradient Descent(748/999): loss=8.96689972967367, w0=-3.6299817304602713, w1=1.1663312367127916\n",
            "Gradient Descent(749/999): loss=8.96680647330518, w0=-3.6309399873267187, w1=1.1664275040090644\n",
            "Gradient Descent(750/999): loss=8.966713888138756, w0=-3.63189478949352, w1=1.1665234242432856\n",
            "Gradient Descent(751/999): loss=8.966621969343501, w0=-3.6328461494155286, w1=1.1666189986666795\n",
            "Gradient Descent(752/999): loss=8.966530712123285, w0=-3.6337940795026977, w1=1.1667142285259613\n",
            "Gradient Descent(753/999): loss=8.966440111716501, w0=-3.6347385921202386, w1=1.1668091150633504\n",
            "Gradient Descent(754/999): loss=8.966350163395802, w0=-3.6356796995887843, w1=1.1669036595165876\n",
            "Gradient Descent(755/999): loss=8.966260862467875, w0=-3.63661741418455, w1=1.1669978631189522\n",
            "Gradient Descent(756/999): loss=8.966172204273189, w0=-3.6375517481394914, w1=1.1670917270992769\n",
            "Gradient Descent(757/999): loss=8.966084184185737, w0=-3.6384827136414675, w1=1.1671852526819644\n",
            "Gradient Descent(758/999): loss=8.965996797612823, w0=-3.6394103228343964, w1=1.1672784410870023\n",
            "Gradient Descent(759/999): loss=8.965910039994794, w0=-3.640334587818415, w1=1.1673712935299818\n",
            "Gradient Descent(760/999): loss=8.96582390680482, w0=-3.641255520650038, w1=1.1674638112221094\n",
            "Gradient Descent(761/999): loss=8.96573839354865, w0=-3.642173133342313, w1=1.1675559953702268\n",
            "Gradient Descent(762/999): loss=8.965653495764384, w0=-3.6430874378649785, w1=1.1676478471768237\n",
            "Gradient Descent(763/999): loss=8.965569209022231, w0=-3.6439984461446198, w1=1.1677393678400552\n",
            "Gradient Descent(764/999): loss=8.965485528924285, w0=-3.644906170064825, w1=1.1678305585537563\n",
            "Gradient Descent(765/999): loss=8.965402451104294, w0=-3.6458106214663397, w1=1.1679214205074588\n",
            "Gradient Descent(766/999): loss=8.965319971227435, w0=-3.6467118121472204, w1=1.1680119548864047\n",
            "Gradient Descent(767/999): loss=8.965238084990073, w0=-3.64760975386299, w1=1.1681021628715649\n",
            "Gradient Descent(768/999): loss=8.965156788119561, w0=-3.6485044583267903, w1=1.1681920456396504\n",
            "Gradient Descent(769/999): loss=8.965076076373995, w0=-3.649395937209535, w1=1.1682816043631319\n",
            "Gradient Descent(770/999): loss=8.96499594554201, w0=-3.650284202140062, w1=1.1683708402102515\n",
            "Gradient Descent(771/999): loss=8.964916391442541, w0=-3.651169264705285, w1=1.1684597543450415\n",
            "Gradient Descent(772/999): loss=8.964837409924625, w0=-3.652051136450345, w1=1.1685483479273353\n",
            "Gradient Descent(773/999): loss=8.964758996867172, w0=-3.6529298288787597, w1=1.1686366221127868\n",
            "Gradient Descent(774/999): loss=8.964681148178748, w0=-3.653805353452575, w1=1.1687245780528828\n",
            "Gradient Descent(775/999): loss=8.964603859797379, w0=-3.6546777215925137, w1=1.1688122168949586\n",
            "Gradient Descent(776/999): loss=8.96452712769031, w0=-3.6555469446781252, w1=1.168899539782213\n",
            "Gradient Descent(777/999): loss=8.964450947853827, w0=-3.656413034047933, w1=1.1689865478537247\n",
            "Gradient Descent(778/999): loss=8.964375316313022, w0=-3.657276000999583, w1=1.1690732422444636\n",
            "Gradient Descent(779/999): loss=8.964300229121605, w0=-3.658135856789991, w1=1.16915962408531\n",
            "Gradient Descent(780/999): loss=8.964225682361675, w0=-3.6589926126354895, w1=1.1692456945030654\n",
            "Gradient Descent(781/999): loss=8.964151672143544, w0=-3.659846279711974, w1=1.16933145462047\n",
            "Gradient Descent(782/999): loss=8.964078194605511, w0=-3.660696869155049, w1=1.1694169055562162\n",
            "Gradient Descent(783/999): loss=8.964005245913675, w0=-3.6615443920601725, w1=1.169502048424963\n",
            "Gradient Descent(784/999): loss=8.963932822261722, w0=-3.6623888594828014, w1=1.169586884337351\n",
            "Gradient Descent(785/999): loss=8.963860919870736, w0=-3.6632302824385357, w1=1.1696714144000164\n",
            "Gradient Descent(786/999): loss=8.963789534989006, w0=-3.6640686719032622, w1=1.1697556397156066\n",
            "Gradient Descent(787/999): loss=8.963718663891814, w0=-3.6649040388132974, w1=1.1698395613827928\n",
            "Gradient Descent(788/999): loss=8.96364830288126, w0=-3.66573639406553, w1=1.169923180496286\n",
            "Gradient Descent(789/999): loss=8.963578448286048, w0=-3.6665657485175633, w1=1.1700064981468499\n",
            "Gradient Descent(790/999): loss=8.963509096461312, w0=-3.6673921129878577, w1=1.1700895154213165\n",
            "Gradient Descent(791/999): loss=8.963440243788419, w0=-3.66821549825587, w1=1.1701722334025988\n",
            "Gradient Descent(792/999): loss=8.963371886674782, w0=-3.6690359150621954, w1=1.1702546531697062\n",
            "Gradient Descent(793/999): loss=8.963304021553673, w0=-3.669853374108707, w1=1.1703367757977585\n",
            "Gradient Descent(794/999): loss=8.963236644884025, w0=-3.670667886058696, w1=1.1704186023579979\n",
            "Gradient Descent(795/999): loss=8.963169753150266, w0=-3.67147946153701, w1=1.1705001339178067\n",
            "Gradient Descent(796/999): loss=8.963103342862132, w0=-3.6722881111301926, w1=1.170581371540717\n",
            "Gradient Descent(797/999): loss=8.963037410554467, w0=-3.6730938453866195, w1=1.1706623162864287\n",
            "Gradient Descent(798/999): loss=8.96297195278706, w0=-3.6738966748166395, w1=1.1707429692108189\n",
            "Gradient Descent(799/999): loss=8.962906966144464, w0=-3.674696609892708, w1=1.1708233313659606\n",
            "Gradient Descent(800/999): loss=8.962842447235813, w0=-3.6754936610495252, w1=1.1709034038001322\n",
            "Gradient Descent(801/999): loss=8.962778392694643, w0=-3.676287838684173, w1=1.1709831875578331\n",
            "Gradient Descent(802/999): loss=8.962714799178721, w0=-3.67707915315625, w1=1.1710626836797977\n",
            "Gradient Descent(803/999): loss=8.962651663369876, w0=-3.6778676147880054, w1=1.1711418932030078\n",
            "Gradient Descent(804/999): loss=8.96258898197381, w0=-3.6786532338644755, w1=1.1712208171607068\n",
            "Gradient Descent(805/999): loss=8.962526751719937, w0=-3.679436020633617, w1=1.171299456582413\n",
            "Gradient Descent(806/999): loss=8.962464969361212, w0=-3.6802159853064405, w1=1.1713778124939334\n",
            "Gradient Descent(807/999): loss=8.962403631673967, w0=-3.680993138057144, w1=1.1714558859173763\n",
            "Gradient Descent(808/999): loss=8.962342735457726, w0=-3.6817674890232452, w1=1.1715336778711656\n",
            "Gradient Descent(809/999): loss=8.96228227753505, w0=-3.682539048305715, w1=1.1716111893700532\n",
            "Gradient Descent(810/999): loss=8.962222254751373, w0=-3.6833078259691083, w1=1.1716884214251329\n",
            "Gradient Descent(811/999): loss=8.962162663974834, w0=-3.6840738320416944, w1=1.1717653750438528\n",
            "Gradient Descent(812/999): loss=8.962103502096106, w0=-3.6848370765155893, w1=1.1718420512300298\n",
            "Gradient Descent(813/999): loss=8.962044766028251, w0=-3.6855975693468856, w1=1.1719184509838614\n",
            "Gradient Descent(814/999): loss=8.961986452706538, w0=-3.686355320455782, w1=1.1719945753019387\n",
            "Gradient Descent(815/999): loss=8.961928559088307, w0=-3.687110339726714, w1=1.1720704251772607\n",
            "Gradient Descent(816/999): loss=8.961871082152784, w0=-3.68786263700848, w1=1.1721460015992464\n",
            "Gradient Descent(817/999): loss=8.961814018900945, w0=-3.688612222114373, w1=1.172221305553747\n",
            "Gradient Descent(818/999): loss=8.961757366355348, w0=-3.689359104822307, w1=1.1722963380230598\n",
            "Gradient Descent(819/999): loss=8.961701121559985, w0=-3.690103294874944, w1=1.1723710999859418\n",
            "Gradient Descent(820/999): loss=8.961645281580116, w0=-3.6908448019798232, w1=1.1724455924176198\n",
            "Gradient Descent(821/999): loss=8.961589843502132, w0=-3.6915836358094847, w1=1.1725198162898058\n",
            "Gradient Descent(822/999): loss=8.961534804433386, w0=-3.6923198060015983, w1=1.172593772570708\n",
            "Gradient Descent(823/999): loss=8.961480161502058, w0=-3.6930533221590878, w1=1.1726674622250446\n",
            "Gradient Descent(824/999): loss=8.96142591185699, w0=-3.6937841938502567, w1=1.172740886214055\n",
            "Gradient Descent(825/999): loss=8.96137205266755, w0=-3.6945124306089125, w1=1.1728140454955138\n",
            "Gradient Descent(826/999): loss=8.961318581123484, w0=-3.695238041934492, w1=1.1728869410237428\n",
            "Gradient Descent(827/999): loss=8.961265494434748, w0=-3.6959610372921854, w1=1.1729595737496221\n",
            "Gradient Descent(828/999): loss=8.961212789831402, w0=-3.696681426113057, w1=1.173031944620606\n",
            "Gradient Descent(829/999): loss=8.961160464563422, w0=-3.697399217794173, w1=1.1731040545807299\n",
            "Gradient Descent(830/999): loss=8.961108515900582, w0=-3.6981144216987185, w1=1.1731759045706285\n",
            "Gradient Descent(831/999): loss=8.961056941132322, w0=-3.6988270471561244, w1=1.1732474955275438\n",
            "Gradient Descent(832/999): loss=8.961005737567566, w0=-3.699537103462187, w1=1.1733188283853397\n",
            "Gradient Descent(833/999): loss=8.960954902534624, w0=-3.7002445998791895, w1=1.1733899040745128\n",
            "Gradient Descent(834/999): loss=8.960904433381032, w0=-3.700949545636022, w1=1.1734607235222052\n",
            "Gradient Descent(835/999): loss=8.960854327473411, w0=-3.7016519499283036, w1=1.1735312876522168\n",
            "Gradient Descent(836/999): loss=8.960804582197348, w0=-3.702351821918501, w1=1.1736015973850167\n",
            "Gradient Descent(837/999): loss=8.960755194957226, w0=-3.7030491707360484, w1=1.1736716536377554\n",
            "Gradient Descent(838/999): loss=8.960706163176129, w0=-3.703744005477467, w1=1.173741457324277\n",
            "Gradient Descent(839/999): loss=8.960657484295684, w0=-3.7044363352064824, w1=1.1738110093551317\n",
            "Gradient Descent(840/999): loss=8.960609155775924, w0=-3.705126168954145, w1=1.1738803106375857\n",
            "Gradient Descent(841/999): loss=8.960561175095169, w0=-3.7058135157189454, w1=1.1739493620756356\n",
            "Gradient Descent(842/999): loss=8.96051353974989, w0=-3.706498384466934, w1=1.174018164570018\n",
            "Gradient Descent(843/999): loss=8.96046624725457, w0=-3.7071807841318365, w1=1.1740867190182227\n",
            "Gradient Descent(844/999): loss=8.96041929514159, w0=-3.7078607236151697, w1=1.1741550263145037\n",
            "Gradient Descent(845/999): loss=8.960372680961084, w0=-3.7085382117863603, w1=1.1742230873498911\n",
            "Gradient Descent(846/999): loss=8.960326402280824, w0=-3.7092132574828582, w1=1.1742909030122024\n",
            "Gradient Descent(847/999): loss=8.960280456686084, w0=-3.7098858695102526, w1=1.1743584741860547\n",
            "Gradient Descent(848/999): loss=8.960234841779515, w0=-3.710556056642387, w1=1.174425801752876\n",
            "Gradient Descent(849/999): loss=8.960189555181033, w0=-3.711223827621474, w1=1.1744928865909157\n",
            "Gradient Descent(850/999): loss=8.960144594527675, w0=-3.7118891911582077, w1=1.1745597295752581\n",
            "Gradient Descent(851/999): loss=8.96009995747349, w0=-3.7125521559318795, w1=1.174626331577832\n",
            "Gradient Descent(852/999): loss=8.960055641689406, w0=-3.71321273059049, w1=1.1746926934674229\n",
            "Gradient Descent(853/999): loss=8.960011644863123, w0=-3.7138709237508616, w1=1.174758816109684\n",
            "Gradient Descent(854/999): loss=8.959967964698974, w0=-3.7145267439987526, w1=1.1748247003671477\n",
            "Gradient Descent(855/999): loss=8.959924598917821, w0=-3.715180199888967, w1=1.1748903470992373\n",
            "Gradient Descent(856/999): loss=8.959881545256932, w0=-3.715831299945467, w1=1.1749557571622766\n",
            "Gradient Descent(857/999): loss=8.959838801469852, w0=-3.7164800526614843, w1=1.175020931409504\n",
            "Gradient Descent(858/999): loss=8.959796365326303, w0=-3.717126466499632, w1=1.1750858706910792\n",
            "Gradient Descent(859/999): loss=8.959754234612053, w0=-3.717770549892013, w1=1.1751505758540997\n",
            "Gradient Descent(860/999): loss=8.95971240712881, w0=-3.7184123112403307, w1=1.1752150477426069\n",
            "Gradient Descent(861/999): loss=8.959670880694105, w0=-3.719051758915999, w1=1.1752792871976006\n",
            "Gradient Descent(862/999): loss=8.959629653141173, w0=-3.7196889012602505, w1=1.1753432950570482\n",
            "Gradient Descent(863/999): loss=8.959588722318852, w0=-3.720323746584248, w1=1.1754070721558956\n",
            "Gradient Descent(864/999): loss=8.959548086091454, w0=-3.7209563031691886, w1=1.1754706193260793\n",
            "Gradient Descent(865/999): loss=8.95950774233866, w0=-3.721586579266416, w1=1.1755339373965363\n",
            "Gradient Descent(866/999): loss=8.959467688955428, w0=-3.722214583097525, w1=1.1755970271932146\n",
            "Gradient Descent(867/999): loss=8.959427923851848, w0=-3.7228403228544704, w1=1.1756598895390855\n",
            "Gradient Descent(868/999): loss=8.959388444953063, w0=-3.723463806699674, w1=1.175722525254152\n",
            "Gradient Descent(869/999): loss=8.959349250199146, w0=-3.7240850427661294, w1=1.1757849351554626\n",
            "Gradient Descent(870/999): loss=8.959310337544999, w0=-3.7247040391575097, w1=1.1758471200571183\n",
            "Gradient Descent(871/999): loss=8.959271704960237, w0=-3.7253208039482733, w1=1.175909080770286\n",
            "Gradient Descent(872/999): loss=8.959233350429098, w0=-3.7259353451837676, w1=1.1759708181032087\n",
            "Gradient Descent(873/999): loss=8.95919527195032, w0=-3.726547670880336, w1=1.1760323328612148\n",
            "Gradient Descent(874/999): loss=8.959157467537045, w0=-3.72715778902542, w1=1.1760936258467294\n",
            "Gradient Descent(875/999): loss=8.95911993521672, w0=-3.727765707577667, w1=1.1761546978592845\n",
            "Gradient Descent(876/999): loss=8.959082673030991, w0=-3.7283714344670296, w1=1.1762155496955309\n",
            "Gradient Descent(877/999): loss=8.959045679035587, w0=-3.728974977594873, w1=1.1762761821492451\n",
            "Gradient Descent(878/999): loss=8.959008951300246, w0=-3.729576344834076, w1=1.1763365960113448\n",
            "Gradient Descent(879/999): loss=8.958972487908587, w0=-3.730175544029134, w1=1.176396792069893\n",
            "Gradient Descent(880/999): loss=8.958936286958028, w0=-3.730772582996262, w1=1.1764567711101144\n",
            "Gradient Descent(881/999): loss=8.958900346559684, w0=-3.731367469523495, w1=1.176516533914401\n",
            "Gradient Descent(882/999): loss=8.958864664838252, w0=-3.731960211370792, w1=1.1765760812623254\n",
            "Gradient Descent(883/999): loss=8.958829239931937, w0=-3.732550816270135, w1=1.1766354139306483\n",
            "Gradient Descent(884/999): loss=8.95879406999234, w0=-3.7331392919256303, w1=1.1766945326933316\n",
            "Gradient Descent(885/999): loss=8.958759153184376, w0=-3.733725646013611, w1=1.1767534383215457\n",
            "Gradient Descent(886/999): loss=8.95872448768615, w0=-3.7343098861827335, w1=1.176812131583681\n",
            "Gradient Descent(887/999): loss=8.958690071688888, w0=-3.7348920200540814, w1=1.1768706132453584\n",
            "Gradient Descent(888/999): loss=8.958655903396842, w0=-3.7354720552212615, w1=1.1769288840694379\n",
            "Gradient Descent(889/999): loss=8.958621981027179, w0=-3.7360499992505045, w1=1.1769869448160293\n",
            "Gradient Descent(890/999): loss=8.958588302809899, w0=-3.736625859680763, w1=1.1770447962425021\n",
            "Gradient Descent(891/999): loss=8.958554866987745, w0=-3.7371996440238116, w1=1.177102439103496\n",
            "Gradient Descent(892/999): loss=8.958521671816104, w0=-3.737771359764342, w1=1.177159874150929\n",
            "Gradient Descent(893/999): loss=8.958488715562927, w0=-3.738341014360062, w1=1.1772171021340094\n",
            "Gradient Descent(894/999): loss=8.958455996508617, w0=-3.7389086152417947, w1=1.177274123799243\n",
            "Gradient Descent(895/999): loss=8.958423512945966, w0=-3.739474169813572, w1=1.1773309398904461\n",
            "Gradient Descent(896/999): loss=8.95839126318005, w0=-3.740037685452734, w1=1.1773875511487515\n",
            "Gradient Descent(897/999): loss=8.958359245528147, w0=-3.7405991695100234, w1=1.177443958312622\n",
            "Gradient Descent(898/999): loss=8.958327458319637, w0=-3.7411586293096817, w1=1.1775001621178565\n",
            "Gradient Descent(899/999): loss=8.958295899895935, w0=-3.7417160721495457, w1=1.1775561632976022\n",
            "Gradient Descent(900/999): loss=8.958264568610385, w0=-3.7422715053011424, w1=1.1776119625823627\n",
            "Gradient Descent(901/999): loss=8.958233462828186, w0=-3.742824936009783, w1=1.177667560700008\n",
            "Gradient Descent(902/999): loss=8.958202580926304, w0=-3.743376371494658, w1=1.1777229583757844\n",
            "Gradient Descent(903/999): loss=8.958171921293392, w0=-3.7439258189489317, w1=1.1777781563323229\n",
            "Gradient Descent(904/999): loss=8.958141482329683, w0=-3.744473285539835, w1=1.17783315528965\n",
            "Gradient Descent(905/999): loss=8.958111262446943, w0=-3.74501877840876, w1=1.1778879559651956\n",
            "Gradient Descent(906/999): loss=8.958081260068361, w0=-3.745562304671353, w1=1.1779425590738037\n",
            "Gradient Descent(907/999): loss=8.958051473628476, w0=-3.7461038714176067, w1=1.1779969653277411\n",
            "Gradient Descent(908/999): loss=8.95802190157309, w0=-3.7466434857119526, w1=1.1780511754367065\n",
            "Gradient Descent(909/999): loss=8.9579925423592, w0=-3.7471811545933544, w1=1.17810519010784\n",
            "Gradient Descent(910/999): loss=8.957963394454898, w0=-3.747716885075399, w1=1.1781590100457326\n",
            "Gradient Descent(911/999): loss=8.957934456339315, w0=-3.7482506841463863, w1=1.178212635952435\n",
            "Gradient Descent(912/999): loss=8.957905726502515, w0=-3.7487825587694243, w1=1.1782660685274666\n",
            "Gradient Descent(913/999): loss=8.957877203445435, w0=-3.7493125158825165, w1=1.1783193084678254\n",
            "Gradient Descent(914/999): loss=8.957848885679805, w0=-3.7498405623986537, w1=1.178372356467996\n",
            "Gradient Descent(915/999): loss=8.957820771728063, w0=-3.750366705205904, w1=1.17842521321996\n",
            "Gradient Descent(916/999): loss=8.957792860123279, w0=-3.7508909511675026, w1=1.1784778794132031\n",
            "Gradient Descent(917/999): loss=8.957765149409084, w0=-3.751413307121942, w1=1.1785303557347269\n",
            "Gradient Descent(918/999): loss=8.957737638139594, w0=-3.7519337798830596, w1=1.178582642869055\n",
            "Gradient Descent(919/999): loss=8.957710324879326, w0=-3.7524523762401287, w1=1.178634741498243\n",
            "Gradient Descent(920/999): loss=8.95768320820313, w0=-3.7529691029579455, w1=1.1786866523018884\n",
            "Gradient Descent(921/999): loss=8.957656286696116, w0=-3.7534839667769178, w1=1.1787383759571388\n",
            "Gradient Descent(922/999): loss=8.95762955895358, w0=-3.7539969744131527, w1=1.1787899131386992\n",
            "Gradient Descent(923/999): loss=8.957603023580916, w0=-3.754508132558545, w1=1.1788412645188435\n",
            "Gradient Descent(924/999): loss=8.957576679193572, w0=-3.7550174478808636, w1=1.1788924307674211\n",
            "Gradient Descent(925/999): loss=8.957550524416948, w0=-3.7555249270238384, w1=1.1789434125518672\n",
            "Gradient Descent(926/999): loss=8.957524557886344, w0=-3.756030576607248, w1=1.17899421053721\n",
            "Gradient Descent(927/999): loss=8.957498778246881, w0=-3.756534403227006, w1=1.1790448253860806\n",
            "Gradient Descent(928/999): loss=8.95747318415343, w0=-3.7570364134552445, w1=1.1790952577587208\n",
            "Gradient Descent(929/999): loss=8.95744777427055, w0=-3.757536613840404, w1=1.179145508312993\n",
            "Gradient Descent(930/999): loss=8.957422547272397, w0=-3.758035010907315, w1=1.1791955777043868\n",
            "Gradient Descent(931/999): loss=8.957397501842687, w0=-3.758531611157286, w1=1.179245466586029\n",
            "Gradient Descent(932/999): loss=8.957372636674599, w0=-3.759026421068186, w1=1.1792951756086922\n",
            "Gradient Descent(933/999): loss=8.95734795047072, w0=-3.759519447094531, w1=1.1793447054208024\n",
            "Gradient Descent(934/999): loss=8.957323441942975, w0=-3.7600106956675656, w1=1.1793940566684478\n",
            "Gradient Descent(935/999): loss=8.957299109812563, w0=-3.7605001731953505, w1=1.1794432299953879\n",
            "Gradient Descent(936/999): loss=8.957274952809883, w0=-3.7609878860628427, w1=1.1794922260430603\n",
            "Gradient Descent(937/999): loss=8.957250969674472, w0=-3.7614738406319814, w1=1.1795410454505912\n",
            "Gradient Descent(938/999): loss=8.957227159154941, w0=-3.7619580432417687, w1=1.1795896888548023\n",
            "Gradient Descent(939/999): loss=8.957203520008909, w0=-3.7624405002083536, w1=1.1796381568902188\n",
            "Gradient Descent(940/999): loss=8.957180051002933, w0=-3.762921217825115, w1=1.1796864501890791\n",
            "Gradient Descent(941/999): loss=8.957156750912446, w0=-3.7634002023627415, w1=1.1797345693813421\n",
            "Gradient Descent(942/999): loss=8.957133618521702, w0=-3.7638774600693163, w1=1.1797825150946952\n",
            "Gradient Descent(943/999): loss=8.957110652623701, w0=-3.764352997170396, w1=1.1798302879545635\n",
            "Gradient Descent(944/999): loss=8.957087852020134, w0=-3.7648268198690933, w1=1.1798778885841164\n",
            "Gradient Descent(945/999): loss=8.957065215521304, w0=-3.765298934346157, w1=1.1799253176042774\n",
            "Gradient Descent(946/999): loss=8.957042741946093, w0=-3.7657693467600537, w1=1.1799725756337314\n",
            "Gradient Descent(947/999): loss=8.957020430121872, w0=-3.766238063247047, w1=1.1800196632889326\n",
            "Gradient Descent(948/999): loss=8.956998278884463, w0=-3.766705089921279, w1=1.1800665811841127\n",
            "Gradient Descent(949/999): loss=8.956976287078056, w0=-3.767170432874848, w1=1.1801133299312891\n",
            "Gradient Descent(950/999): loss=8.956954453555166, w0=-3.76763409817789, w1=1.1801599101402733\n",
            "Gradient Descent(951/999): loss=8.956932777176567, w0=-3.7680960918786566, w1=1.180206322418677\n",
            "Gradient Descent(952/999): loss=8.956911256811228, w0=-3.768556420003594, w1=1.1802525673719226\n",
            "Gradient Descent(953/999): loss=8.956889891336262, w0=-3.7690150885574223, w1=1.1802986456032492\n",
            "Gradient Descent(954/999): loss=8.956868679636862, w0=-3.769472103523214, w1=1.1803445577137215\n",
            "Gradient Descent(955/999): loss=8.956847620606252, w0=-3.7699274708624704, w1=1.1803903043022363\n",
            "Gradient Descent(956/999): loss=8.95682671314561, w0=-3.770381196515201, w1=1.1804358859655333\n",
            "Gradient Descent(957/999): loss=8.956805956164027, w0=-3.7708332864000003, w1=1.180481303298198\n",
            "Gradient Descent(958/999): loss=8.956785348578453, w0=-3.771283746414125, w1=1.180526556892675\n",
            "Gradient Descent(959/999): loss=8.956764889313623, w0=-3.7717325824335717, w1=1.1805716473392711\n",
            "Gradient Descent(960/999): loss=8.95674457730202, w0=-3.772179800313152, w1=1.1806165752261664\n",
            "Gradient Descent(961/999): loss=8.9567244114838, w0=-3.7726254058865707, w1=1.180661341139419\n",
            "Gradient Descent(962/999): loss=8.956704390806754, w0=-3.7730694049665, w1=1.1807059456629752\n",
            "Gradient Descent(963/999): loss=8.956684514226248, w0=-3.773511803344657, w1=1.180750389378676\n",
            "Gradient Descent(964/999): loss=8.956664780705161, w0=-3.7739526067918785, w1=1.1807946728662644\n",
            "Gradient Descent(965/999): loss=8.956645189213841, w0=-3.774391821058196, w1=1.1808387967033935\n",
            "Gradient Descent(966/999): loss=8.956625738730043, w0=-3.7748294518729115, w1=1.1808827614656334\n",
            "Gradient Descent(967/999): loss=8.956606428238882, w0=-3.775265504944671, w1=1.1809265677264804\n",
            "Gradient Descent(968/999): loss=8.956587256732778, w0=-3.7756999859615403, w1=1.1809702160573616\n",
            "Gradient Descent(969/999): loss=8.956568223211404, w0=-3.776132900591079, w1=1.1810137070276452\n",
            "Gradient Descent(970/999): loss=8.956549326681625, w0=-3.776564254480413, w1=1.1810570412046462\n",
            "Gradient Descent(971/999): loss=8.956530566157465, w0=-3.7769940532563107, w1=1.1811002191536344\n",
            "Gradient Descent(972/999): loss=8.956511940660032, w0=-3.777422302525253, w1=1.1811432414378416\n",
            "Gradient Descent(973/999): loss=8.956493449217493, w0=-3.77784900787351, w1=1.1811861086184696\n",
            "Gradient Descent(974/999): loss=8.956475090865004, w0=-3.778274174867212, w1=1.181228821254696\n",
            "Gradient Descent(975/999): loss=8.95645686464466, w0=-3.7786978090524213, w1=1.1812713799036836\n",
            "Gradient Descent(976/999): loss=8.956438769605457, w0=-3.7791199159552065, w1=1.181313785120585\n",
            "Gradient Descent(977/999): loss=8.956420804803233, w0=-3.7795405010817134, w1=1.1813560374585534\n",
            "Gradient Descent(978/999): loss=8.956402969300624, w0=-3.7799595699182373, w1=1.181398137468746\n",
            "Gradient Descent(979/999): loss=8.95638526216701, w0=-3.780377127931294, w1=1.1814400857003333\n",
            "Gradient Descent(980/999): loss=8.956367682478469, w0=-3.780793180567692, w1=1.181481882700507\n",
            "Gradient Descent(981/999): loss=8.956350229317732, w0=-3.781207733254602, w1=1.1815235290144848\n",
            "Gradient Descent(982/999): loss=8.956332901774122, w0=-3.78162079139963, w1=1.1815650251855196\n",
            "Gradient Descent(983/999): loss=8.956315698943532, w0=-3.7820323603908856, w1=1.1816063717549055\n",
            "Gradient Descent(984/999): loss=8.956298619928354, w0=-3.7824424455970536, w1=1.1816475692619848\n",
            "Gradient Descent(985/999): loss=8.956281663837439, w0=-3.7828510523674637, w1=1.181688618244156\n",
            "Gradient Descent(986/999): loss=8.95626482978605, w0=-3.78325818603216, w1=1.1817295192368795\n",
            "Gradient Descent(987/999): loss=8.956248116895829, w0=-3.7836638519019705, w1=1.1817702727736863\n",
            "Gradient Descent(988/999): loss=8.956231524294726, w0=-3.7840680552685777, w1=1.1818108793861821\n",
            "Gradient Descent(989/999): loss=8.956215051116976, w0=-3.7844708014045856, w1=1.1818513396040586\n",
            "Gradient Descent(990/999): loss=8.95619869650304, w0=-3.78487209556359, w1=1.1818916539550954\n",
            "Gradient Descent(991/999): loss=8.956182459599576, w0=-3.785271942980246, w1=1.181931822965171\n",
            "Gradient Descent(992/999): loss=8.956166339559369, w0=-3.7856703488703376, w1=1.181971847158267\n",
            "Gradient Descent(993/999): loss=8.956150335541311, w0=-3.7860673184308435, w1=1.1820117270564765\n",
            "Gradient Descent(994/999): loss=8.956134446710351, w0=-3.7864628568400076, w1=1.1820514631800105\n",
            "Gradient Descent(995/999): loss=8.956118672237434, w0=-3.786856969257405, w1=1.1820910560472038\n",
            "Gradient Descent(996/999): loss=8.956103011299486, w0=-3.7872496608240085, w1=1.1821305061745233\n",
            "Gradient Descent(997/999): loss=8.956087463079355, w0=-3.787640936662258, w1=1.1821698140765735\n",
            "Gradient Descent(998/999): loss=8.95607202676576, w0=-3.7880308018761255, w1=1.1822089802661038\n",
            "Gradient Descent(999/999): loss=8.956056701553273, w0=-3.7884192615511822, w1=1.1822480052540147\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([-3.78841926,  1.18224801])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g, cost = gradientDescent(X, y, theta, alpha, iters)\n",
        "g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we can compute the cost (error) of the trained model using our fitted parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(8.956041486642253)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "computeCost(X, y, g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's plot the linear model along with the data to visually see how well it fits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Predicted Profit vs. Population Size')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = np.linspace(data.Population.min(), data.Population.max(), 100)\n",
        "f = g[0] + (g[1] * x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(x, f, 'r', label='Prediction')\n",
        "ax.scatter(data.Population, data.Profit, label='Traning Data')\n",
        "ax.legend(loc=2)\n",
        "ax.set_xlabel('Population')\n",
        "ax.set_ylabel('Profit')\n",
        "ax.set_title('Predicted Profit vs. Population Size')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks pretty good!  Since the gradient decent function also outputs a vector with the cost at each training iteration, we can plot that as well.  Notice that the cost always decreases - this is an example of a convex optimization problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Error vs. Training Epoch')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(np.arange(iters), cost, 'r')\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_ylabel('Cost')\n",
        "ax.set_title('Error vs. Training Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
